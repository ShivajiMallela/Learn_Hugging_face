{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting .env\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What we're going to build\n",
    "\n",
    "We're going to be bulding a `food`/`not_food` **text classification model**. \n",
    "\n",
    "Given a piece of a text (such as an image caption), our model will be able to predict if it's about food or not.\n",
    "\n",
    "More specifically, we're going to follow the following steps:\n",
    "\n",
    "1. **[Data](https://huggingface.co/datasets/mrdbourke/learn_hf_food_not_food_image_captions): Problem defintion and dataset preparation** - Getting a dataset/setting up the problem space.\n",
    "2. **[Model](https://huggingface.co/mrdbourke/learn_hf_food_not_food_text_classifier-distilbert-base-uncased): Finding, training and evaluating a model** - Finding a text classification model suitable for our problem on Hugging Face and customizing it to our own dataset.\n",
    "3. **[Demo](https://huggingface.co/spaces/mrdbourke/learn_hf_food_not_food_text_classifier_demo): Creating a demo and put our model into the real world** - Sharing our trained model in a way others can access and use.\n",
    "\n",
    "By the end of this project, you'll have a trained model and [demo on Hugging Face](https://huggingface.co/spaces/mrdbourke/learn_hf_food_not_food_text_classifier_demo) you can share with others:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers version: 4.44.2\n",
      "Datasets version: 3.0.0\n",
      "Torch version: 2.4.1+cu121\n"
     ]
    }
   ],
   "source": [
    "# install dependencies\n",
    "try:\n",
    "    import datasets, evaluate, accelerate\n",
    "    import gradio as gr\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -U datasets, evaluate, accelerate, gradio\n",
    "    import datasets, evaluate, accelerate\n",
    "    import gradio as gr\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "print(f\"Transformers version: {transformers.__version__}\")\n",
    "print(f\"Datasets version: {datasets.__version__}\")\n",
    "print(f\"Torch version: {torch.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset from hugging face hub\n",
    "dataset = datasets.load_dataset(path=\"mrdbourke/learn_hf_food_not_food_image_captions\")\n",
    "\n",
    "# inspect the dataset\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['text', 'label']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what features are there\n",
    "dataset.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 250\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the training split\n",
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Creamy cauliflower curry with garlic naan, featuring tender cauliflower in a rich sauce with cream and spices, served with garlic naan bread.',\n",
       " 'label': 'food'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect random examples from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Random samples from dataset:\n",
      "\n",
      "Text: A slice of pizza with a spicy kick, featuring jalapeno peppers | Label: food\n",
      "Text: Set of potholders stored in a drawer | Label: not_food\n",
      "Text: A slice of juicy watermelon with a sprinkle of chili powder and lime juice | Label: food\n",
      "Text: King-size bed with a white comforter inviting a good night's sleep | Label: not_food\n",
      "Text: Set of tools organized in a garage | Label: not_food\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random_indexes = random.sample(range(len(dataset['train'])), 5)\n",
    "random_samples  = dataset['train'][random_indexes]\n",
    "\n",
    "print(f\"[INFO] Random samples from dataset:\\n\")\n",
    "for item in zip(random_samples['text'], random_samples['label']):\n",
    "    print(f\"Text: {item[0]} | Label: {item[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['food', 'not_food']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unique label values\n",
    "dataset['train'].unique('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'food': 125, 'not_food': 125})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check number of each label\n",
    "from collections import Counter\n",
    "\n",
    "Counter(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Creamy cauliflower curry with garlic naan, fea...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Set of books stacked on a desk</td>\n",
       "      <td>not_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Watching TV together, a family has their dog s...</td>\n",
       "      <td>not_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wooden dresser with a mirror reflecting the room</td>\n",
       "      <td>not_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lawn mower stored in a shed</td>\n",
       "      <td>not_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Standing floor lamp providing light next to an...</td>\n",
       "      <td>not_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Luxurious coconut shrimp curry on a generous p...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Barbecue grill waiting on a patio</td>\n",
       "      <td>not_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Family gathered around a dining table, laughin...</td>\n",
       "      <td>not_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Taking a nap on a hammock, a man has his dog s...</td>\n",
       "      <td>not_food</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text     label\n",
       "0    Creamy cauliflower curry with garlic naan, fea...      food\n",
       "1                       Set of books stacked on a desk  not_food\n",
       "2    Watching TV together, a family has their dog s...  not_food\n",
       "3     Wooden dresser with a mirror reflecting the room  not_food\n",
       "4                          Lawn mower stored in a shed  not_food\n",
       "..                                                 ...       ...\n",
       "245  Standing floor lamp providing light next to an...  not_food\n",
       "246  Luxurious coconut shrimp curry on a generous p...      food\n",
       "247                  Barbecue grill waiting on a patio  not_food\n",
       "248  Family gathered around a dining table, laughin...  not_food\n",
       "249  Taking a nap on a hammock, a man has his dog s...  not_food\n",
       "\n",
       "[250 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn our dataset into a DataFrame and get a random sample\n",
    "food_not_food_df = pd.DataFrame(dataset['train'])\n",
    "food_not_food_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "food        125\n",
       "not_food    125\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the value counts of the label column\n",
    "food_not_food_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a mapping from labels to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 'not_food', '1': 'food'}\n",
      "{'not_food': '0', 'food': '1'}\n"
     ]
    }
   ],
   "source": [
    "# Create mapping from id2label and label2id\n",
    "id2label = {'0': 'not_food', '1' : 'food'}\n",
    "label2id = {'not_food' : '0', 'food' : '1'}\n",
    "\n",
    "print(id2label)\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID to Label mapping: {0: 'not_food', 1: 'food'}\n",
      "Label to ID mapping: {'not_food': 0, 'food': 1}\n"
     ]
    }
   ],
   "source": [
    "# Create mappings programmatically from dataset\n",
    "id2label = {idx: label for idx, label in enumerate(dataset['train'].unique('label')[::-1])}\n",
    "label2id = {label: idx for idx, label in id2label.items()}\n",
    "\n",
    "print(f\"ID to Label mapping: {id2label}\")\n",
    "print(f\"Label to ID mapping: {label2id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I love eating chicken.', 'label': 1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn labels into 0 or 1 (e.g. 0 for \"not_food\", 1 for \"food\")\n",
    "def map_labels_to_number(example):\n",
    "    example['label'] = label2id[example['label']]\n",
    "\n",
    "    return example\n",
    "\n",
    "example_sample = {\"text\": \"I love eating chicken.\", \"label\": \"food\"}\n",
    "\n",
    "# Test the function \n",
    "map_labels_to_number(example_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['Creamy cauliflower curry with garlic naan, featuring tender cauliflower in a rich sauce with cream and spices, served with garlic naan bread.',\n",
       "  'Set of books stacked on a desk',\n",
       "  'Watching TV together, a family has their dog stretched out on the floor',\n",
       "  'Wooden dresser with a mirror reflecting the room',\n",
       "  'Lawn mower stored in a shed'],\n",
       " 'label': [1, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map our dataset labels to numbers\n",
    "dataset = dataset[\"train\"].map(map_labels_to_number)\n",
    "dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['Set of speakers perched on a shelf',\n",
       "  'Kohlrabi in a bowl, sprinkled with salt and served with a side of yogurt dip for a tasty, unique snack.',\n",
       "  'Spicy prawn curry with fresh mint garnish, featuring juicy prawns in a fiery sauce with onions and tomatoes, finished with mint leaves.',\n",
       "  'Sweet and savory sushi roll with ingredients like mango and shrimp.',\n",
       "  'A cat and a dog sitting on a couch'],\n",
       " 'label': [0, 1, 1, 1, 0]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle the dataset and view the first 5 samples (will return different results each time) \n",
    "dataset.shuffle()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Random sample from training dataset:\n",
      "Text: Pizza with a unique crust, such as cauliflower or zucchini, for a healthier option\n",
      "Label: 1 (food)\n",
      "\n",
      "[INFO] Random sample from testing dataset:\n",
      "Text: Comforting lamb curry bowl, featuring tender lamb slow-cooked in a flavorful sauce with cumin and coriander, garnished with toasted cumin seeds.\n",
      "Label: 1 (food)\n"
     ]
    }
   ],
   "source": [
    "random_idx_train = random.randint(0, len(dataset['train']))\n",
    "random_sample_train = dataset['train'][random_idx_train]\n",
    "\n",
    "random_idx_test = random.randint(0, len(dataset['test']))\n",
    "random_sample_test = dataset['test'][random_idx_test]\n",
    "\n",
    "print(f\"[INFO] Random sample from training dataset:\")\n",
    "print(f\"Text: {random_sample_train['text']}\\nLabel: {random_sample_train['label']} ({id2label[random_sample_train['label']]})\\n\")\n",
    "print(f\"[INFO] Random sample from testing dataset:\")\n",
    "print(f\"Text: {random_sample_test['text']}\\nLabel: {random_sample_test['label']} ({id2label[random_sample_test['label']]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spadmin/miniconda3/envs/tf217/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertTokenizerFast(name_or_path='distilbert/distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=\"distilbert/distilbert-base-uncased\",\n",
    "                                          use_fast = True)\n",
    "\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 2293, 10733, 102], 'attention_mask': [1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test out tokenizer\n",
    "tokenizer(\"I love pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 3698, 4083, 102], 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 30522\n",
      "Length of max tokenizer input sequence: 512\n"
     ]
    }
   ],
   "source": [
    "# Get the length of the vocabulary \n",
    "length_of_vocab = len(tokenizer.vocab)\n",
    "print(f\"Length of vocabulary is {length_of_vocab}\")\n",
    "\n",
    "# Get the maximum sequence length the tokenizer can handle\n",
    "max_tokenizer_input_seq = tokenizer.model_max_length\n",
    "print(f\"Length of max tokenizer input sequence: {max_tokenizer_input_seq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7975"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab['chicken']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets error because this word is not in the vocab\n",
    "# tokenizer.vocab['shivaji']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when calling the tokenizer on the word, it will automatically split the word into word pieces or subwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'shiva', '##ji', '[SEP]']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can check what word pieces got broken into with tokenizer.convert_ids_to_tokens(input_ids).\n",
    "tokenizer.convert_ids_to_tokens(tokenizer('shivaji').input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', '[UNK]', '[SEP]']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try to tokenize an emoji\n",
    "tokenizer.convert_ids_to_tokens(tokenizer(\"ðŸ\").input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the tokenizer.vocab is a Python dictionary, we can get a sample of the vocabulary using tokenizer.vocab.items()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('!', 999), ('\"', 1000), ('#', 1001), ('##!', 29612), ('##\"', 29613)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the first 5 items in the tokenizer vocab\n",
    "sorted(tokenizer.vocab.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kay', 10905),\n",
       " ('dwarves', 29281),\n",
       " ('burma', 11050),\n",
       " ('plucked', 20780),\n",
       " ('boasted', 23390)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.sample(sorted(tokenizer.vocab.items()), k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a preprocessing function to tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(examples):\n",
    "    return tokenizer(examples['text'],\n",
    "                     padding=True,\n",
    "                     truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 2293, 7975, 102], 'attention_mask': [1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_sample_2 = {'text':\"I love chicken\", \"label\":1}\n",
    "\n",
    "tokenize_text(example_sample_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 50\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(function=tokenize_text,\n",
    "                                batched=True,\n",
    "                                batch_size=1000)\n",
    "\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Key: text\n",
      "Train sample: Set of headphones placed on a desk\n",
      "Test sample: A slice of pepperoni pizza with a layer of melted cheese\n",
      "\n",
      "[INFO] Key: label\n",
      "Train sample: 0\n",
      "Test sample: 1\n",
      "\n",
      "[INFO] Key: input_ids\n",
      "Train sample: [101, 2275, 1997, 2132, 19093, 2872, 2006, 1037, 4624, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Test sample: [101, 1037, 14704, 1997, 11565, 10698, 10733, 2007, 1037, 6741, 1997, 12501, 8808, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "[INFO] Key: attention_mask\n",
      "Train sample: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Test sample: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get two samples from the tokenized dataset\n",
    "train_tokenized_sample = tokenized_dataset['train'][0]\n",
    "test_tokenized_sample = tokenized_dataset[\"test\"][0]\n",
    "\n",
    "for key in train_tokenized_sample.keys():\n",
    "    print(f\"[INFO] Key: {key}\")\n",
    "    print(f\"Train sample: {train_tokenized_sample[key]}\")\n",
    "    print(f\"Test sample: {test_tokenized_sample[key]}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up an evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "accuracy_metric = evaluate.load('accuracy')\n",
    "\n",
    "def compute_accuracy(predictions_and_labels: Tuple[np.array, np.array]):\n",
    "    predictions, labels = predictions_and_labels\n",
    "\n",
    "    if len(predictions.shape)>=2:\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    return accuracy_metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy when all predictions are correct: {'accuracy': 1.0}\n",
      "Accuracy when one prediction is wrong: {'accuracy': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# Create example list of predictions and labels\n",
    "example_labels = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "example_predictions_all_correct = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "example_predictions_one_wrong = np.array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n",
    "\n",
    "# Test the function\n",
    "print(f\"Accuracy when all predictions are correct: {compute_accuracy((example_predictions_all_correct, example_labels))}\")\n",
    "print(f\"Accuracy when one prediction is wrong: {compute_accuracy((example_predictions_one_wrong, example_labels))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id2label: {0: 'not_food', 1: 'food'}\n",
      "label2id: {'not_food': 0, 'food': 1}\n"
     ]
    }
   ],
   "source": [
    "# Get id and label mappings\n",
    "print(f\"id2label: {id2label}\")\n",
    "print(f\"label2id: {label2id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"distilbert/distilbert-base-uncased\",\n",
    "    num_labels = 2,\n",
    "    id2label = id2label,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try and make a prediction with the loaded model (this will error)\n",
    "# model(**tokenized_dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the model\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting the parameters of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trainable_parameters': 66955010, 'total_parameters': 66955010}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_params(model):\n",
    "    trainable_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total_parameters = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "    return {\"trainable_parameters\": trainable_parameters, \"total_parameters\": total_parameters}\n",
    "\n",
    "# Count the parameters of the model\n",
    "count_params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a directory for saving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('models/learn_hf_food_not_food_classifier-ditsilbert-base-uncased')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create model output directory\n",
    "from pathlib import Path\n",
    "\n",
    "# Create models directory\n",
    "models_dir = Path(\"models\")\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Create model save name\n",
    "model_save_name = \"learn_hf_food_not_food_classifier-ditsilbert-base-uncased\"\n",
    "\n",
    "# create model save path\n",
    "model_save_dir = Path(models_dir, model_save_name)\n",
    "\n",
    "model_save_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up training arguments with TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving model checkpoints to: models/learn_hf_food_not_food_classifier-ditsilbert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "print(f\"[INFO] Saving model checkpoints to: {model_save_dir}\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_save_dir,\n",
    "    learning_rate=0.0001,\n",
    "    per_device_train_batch_size= 32,\n",
    "    per_device_eval_batch_size= 32,\n",
    "    num_train_epochs=10,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    save_total_limit=3,\n",
    "    use_cpu=False,\n",
    "    seed=42,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_strategy='epoch',\n",
    "    report_to='none',\n",
    "    # push_to_hub=True,\n",
    "    # hub_token=\"Token_here\",\n",
    "    hub_private_repo=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "_n_gpu=1,\n",
       "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
       "adafactor=False,\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "auto_find_batch_size=False,\n",
       "batch_eval_metrics=False,\n",
       "bf16=False,\n",
       "bf16_full_eval=False,\n",
       "data_seed=None,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=0,\n",
       "dataloader_persistent_workers=False,\n",
       "dataloader_pin_memory=True,\n",
       "dataloader_prefetch_factor=None,\n",
       "ddp_backend=None,\n",
       "ddp_broadcast_buffers=None,\n",
       "ddp_bucket_cap_mb=None,\n",
       "ddp_find_unused_parameters=None,\n",
       "ddp_timeout=1800,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=False,\n",
       "dispatch_batches=None,\n",
       "do_eval=True,\n",
       "do_predict=False,\n",
       "do_train=False,\n",
       "eval_accumulation_steps=None,\n",
       "eval_delay=0,\n",
       "eval_do_concat_batches=True,\n",
       "eval_on_start=False,\n",
       "eval_steps=None,\n",
       "eval_strategy=IntervalStrategy.EPOCH,\n",
       "eval_use_gather_object=False,\n",
       "evaluation_strategy=None,\n",
       "fp16=False,\n",
       "fp16_backend=auto,\n",
       "fp16_full_eval=False,\n",
       "fp16_opt_level=O1,\n",
       "fsdp=[],\n",
       "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
       "fsdp_min_num_params=0,\n",
       "fsdp_transformer_layer_cls_to_wrap=None,\n",
       "full_determinism=False,\n",
       "gradient_accumulation_steps=1,\n",
       "gradient_checkpointing=False,\n",
       "gradient_checkpointing_kwargs=None,\n",
       "greater_is_better=False,\n",
       "group_by_length=False,\n",
       "half_precision_backend=auto,\n",
       "hub_always_push=False,\n",
       "hub_model_id=None,\n",
       "hub_private_repo=False,\n",
       "hub_strategy=HubStrategy.EVERY_SAVE,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "include_inputs_for_metrics=False,\n",
       "include_num_input_tokens_seen=False,\n",
       "include_tokens_per_second=False,\n",
       "jit_mode_eval=False,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=0.0001,\n",
       "length_column_name=length,\n",
       "load_best_model_at_end=True,\n",
       "local_rank=0,\n",
       "log_level=passive,\n",
       "log_level_replica=warning,\n",
       "log_on_each_node=True,\n",
       "logging_dir=models/learn_hf_food_not_food_classifier-ditsilbert-base-uncased/runs/Nov18_12-13-32_Smalle3-Ai-L,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=500,\n",
       "logging_strategy=IntervalStrategy.EPOCH,\n",
       "lr_scheduler_kwargs={},\n",
       "lr_scheduler_type=SchedulerType.LINEAR,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=-1,\n",
       "metric_for_best_model=loss,\n",
       "mp_parameters=,\n",
       "neftune_noise_alpha=None,\n",
       "no_cuda=False,\n",
       "num_train_epochs=10,\n",
       "optim=OptimizerNames.ADAMW_TORCH,\n",
       "optim_args=None,\n",
       "optim_target_modules=None,\n",
       "output_dir=models/learn_hf_food_not_food_classifier-ditsilbert-base-uncased,\n",
       "overwrite_output_dir=False,\n",
       "past_index=-1,\n",
       "per_device_eval_batch_size=32,\n",
       "per_device_train_batch_size=32,\n",
       "prediction_loss_only=False,\n",
       "push_to_hub=False,\n",
       "push_to_hub_model_id=None,\n",
       "push_to_hub_organization=None,\n",
       "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
       "ray_scope=last,\n",
       "remove_unused_columns=True,\n",
       "report_to=[],\n",
       "restore_callback_states_from_checkpoint=False,\n",
       "resume_from_checkpoint=None,\n",
       "run_name=models/learn_hf_food_not_food_classifier-ditsilbert-base-uncased,\n",
       "save_on_each_node=False,\n",
       "save_only_model=False,\n",
       "save_safetensors=True,\n",
       "save_steps=500,\n",
       "save_strategy=IntervalStrategy.EPOCH,\n",
       "save_total_limit=3,\n",
       "seed=42,\n",
       "skip_memory_metrics=True,\n",
       "split_batches=None,\n",
       "tf32=None,\n",
       "torch_compile=False,\n",
       "torch_compile_backend=None,\n",
       "torch_compile_mode=None,\n",
       "torch_empty_cache_steps=None,\n",
       "torchdynamo=None,\n",
       "tpu_metrics_debug=False,\n",
       "tpu_num_cores=None,\n",
       "use_cpu=False,\n",
       "use_ipex=False,\n",
       "use_legacy_prediction_loop=False,\n",
       "use_mps_device=False,\n",
       "warmup_ratio=0.0,\n",
       "warmup_steps=0,\n",
       "weight_decay=0.0,\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up an instance of Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "# setup trainer\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['test'],\n",
    "    tokenizer = tokenizer,\n",
    "    compute_metrics=compute_accuracy\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training our text classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:12, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.436800</td>\n",
       "      <td>0.167073</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.139100</td>\n",
       "      <td>0.024086</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>0.004223</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.001756</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000769</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train a text classification model\n",
    "results = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_runtime: 12.7685\n",
      "train_samples_per_second: 156.636\n",
      "train_steps_per_second: 5.482\n",
      "total_flos: 18110777160000.0\n",
      "train_loss: 0.06010841992683709\n",
      "epoch: 10.0\n"
     ]
    }
   ],
   "source": [
    "# Inspect training metrics\n",
    "for key, value in results.metrics.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving model to models/learn_hf_food_not_food_classifier-ditsilbert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "### Save the model for later use\n",
    "\n",
    "print(f\"[INFO] Saving model to {model_save_dir}\")\n",
    "trainer.save_model(output_dir=model_save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the model training metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 0.4368,\n",
       "  'grad_norm': 2.5820062160491943,\n",
       "  'learning_rate': 9e-05,\n",
       "  'epoch': 1.0,\n",
       "  'step': 7},\n",
       " {'eval_loss': 0.16707336902618408,\n",
       "  'eval_accuracy': 0.98,\n",
       "  'eval_runtime': 0.0344,\n",
       "  'eval_samples_per_second': 1454.981,\n",
       "  'eval_steps_per_second': 58.199,\n",
       "  'epoch': 1.0,\n",
       "  'step': 7},\n",
       " {'loss': 0.1391,\n",
       "  'grad_norm': 0.5799462199211121,\n",
       "  'learning_rate': 8e-05,\n",
       "  'epoch': 2.0,\n",
       "  'step': 14},\n",
       " {'eval_loss': 0.024085821583867073,\n",
       "  'eval_accuracy': 1.0,\n",
       "  'eval_runtime': 0.0259,\n",
       "  'eval_samples_per_second': 1932.022,\n",
       "  'eval_steps_per_second': 77.281,\n",
       "  'epoch': 2.0,\n",
       "  'step': 14},\n",
       " {'loss': 0.0161,\n",
       "  'grad_norm': 0.10622306913137436,\n",
       "  'learning_rate': 7e-05,\n",
       "  'epoch': 3.0,\n",
       "  'step': 21},\n",
       " {'eval_loss': 0.004223309922963381,\n",
       "  'eval_accuracy': 1.0,\n",
       "  'eval_runtime': 0.0264,\n",
       "  'eval_samples_per_second': 1891.832,\n",
       "  'eval_steps_per_second': 75.673,\n",
       "  'epoch': 3.0,\n",
       "  'step': 21},\n",
       " {'loss': 0.0036,\n",
       "  'grad_norm': 0.0641559585928917,\n",
       "  'learning_rate': 6e-05,\n",
       "  'epoch': 4.0,\n",
       "  'step': 28},\n",
       " {'eval_loss': 0.0017564651789143682,\n",
       "  'eval_accuracy': 1.0,\n",
       "  'eval_runtime': 0.0292,\n",
       "  'eval_samples_per_second': 1714.368,\n",
       "  'eval_steps_per_second': 68.575,\n",
       "  'epoch': 4.0,\n",
       "  'step': 28},\n",
       " {'loss': 0.0016,\n",
       "  'grad_norm': 0.022474119439721107,\n",
       "  'learning_rate': 5e-05,\n",
       "  'epoch': 5.0,\n",
       "  'step': 35},\n",
       " {'eval_loss': 0.0010137524222955108,\n",
       "  'eval_accuracy': 1.0,\n",
       "  'eval_runtime': 0.0286,\n",
       "  'eval_samples_per_second': 1745.59,\n",
       "  'eval_steps_per_second': 69.824,\n",
       "  'epoch': 5.0,\n",
       "  'step': 35},\n",
       " {'loss': 0.001,\n",
       "  'grad_norm': 0.015685684978961945,\n",
       "  'learning_rate': 4e-05,\n",
       "  'epoch': 6.0,\n",
       "  'step': 42},\n",
       " {'eval_loss': 0.0007694819360040128,\n",
       "  'eval_accuracy': 1.0,\n",
       "  'eval_runtime': 0.0281,\n",
       "  'eval_samples_per_second': 1781.823,\n",
       "  'eval_steps_per_second': 71.273,\n",
       "  'epoch': 6.0,\n",
       "  'step': 42},\n",
       " {'loss': 0.0008,\n",
       "  'grad_norm': 0.013560902327299118,\n",
       "  'learning_rate': 3e-05,\n",
       "  'epoch': 7.0,\n",
       "  'step': 49},\n",
       " {'eval_loss': 0.0006540273316204548,\n",
       "  'eval_accuracy': 1.0,\n",
       "  'eval_runtime': 0.0265,\n",
       "  'eval_samples_per_second': 1884.471,\n",
       "  'eval_steps_per_second': 75.379,\n",
       "  'epoch': 7.0,\n",
       "  'step': 49},\n",
       " {'loss': 0.0008,\n",
       "  'grad_norm': 0.014498572796583176,\n",
       "  'learning_rate': 2e-05,\n",
       "  'epoch': 8.0,\n",
       "  'step': 56},\n",
       " {'eval_loss': 0.0005940611008554697,\n",
       "  'eval_accuracy': 1.0,\n",
       "  'eval_runtime': 0.0307,\n",
       "  'eval_samples_per_second': 1629.641,\n",
       "  'eval_steps_per_second': 65.186,\n",
       "  'epoch': 8.0,\n",
       "  'step': 56},\n",
       " {'loss': 0.0007,\n",
       "  'grad_norm': 0.011621275916695595,\n",
       "  'learning_rate': 1e-05,\n",
       "  'epoch': 9.0,\n",
       "  'step': 63},\n",
       " {'eval_loss': 0.0005636667483486235,\n",
       "  'eval_accuracy': 1.0,\n",
       "  'eval_runtime': 0.0267,\n",
       "  'eval_samples_per_second': 1870.019,\n",
       "  'eval_steps_per_second': 74.801,\n",
       "  'epoch': 9.0,\n",
       "  'step': 63},\n",
       " {'loss': 0.0006,\n",
       "  'grad_norm': 0.00963500328361988,\n",
       "  'learning_rate': 0.0,\n",
       "  'epoch': 10.0,\n",
       "  'step': 70},\n",
       " {'eval_loss': 0.0005540283746086061,\n",
       "  'eval_accuracy': 1.0,\n",
       "  'eval_runtime': 0.0268,\n",
       "  'eval_samples_per_second': 1865.644,\n",
       "  'eval_steps_per_second': 74.626,\n",
       "  'epoch': 10.0,\n",
       "  'step': 70},\n",
       " {'train_runtime': 12.7685,\n",
       "  'train_samples_per_second': 156.636,\n",
       "  'train_steps_per_second': 5.482,\n",
       "  'total_flos': 18110777160000.0,\n",
       "  'train_loss': 0.06010841992683709,\n",
       "  'epoch': 10.0,\n",
       "  'step': 70}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.state.log_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 0.4368,\n",
       "  'grad_norm': 2.5820062160491943,\n",
       "  'learning_rate': 9e-05,\n",
       "  'epoch': 1.0,\n",
       "  'step': 7},\n",
       " {'eval_loss': 0.16707336902618408,\n",
       "  'eval_accuracy': 0.98,\n",
       "  'eval_runtime': 0.0344,\n",
       "  'eval_samples_per_second': 1454.981,\n",
       "  'eval_steps_per_second': 58.199,\n",
       "  'epoch': 1.0,\n",
       "  'step': 7},\n",
       " {'loss': 0.1391,\n",
       "  'grad_norm': 0.5799462199211121,\n",
       "  'learning_rate': 8e-05,\n",
       "  'epoch': 2.0,\n",
       "  'step': 14},\n",
       " {'eval_loss': 0.024085821583867073,\n",
       "  'eval_accuracy': 1.0,\n",
       "  'eval_runtime': 0.0259,\n",
       "  'eval_samples_per_second': 1932.022,\n",
       "  'eval_steps_per_second': 77.281,\n",
       "  'epoch': 2.0,\n",
       "  'step': 14}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get training history\n",
    "trainer_history_all = trainer.state.log_history\n",
    "trainer_history_metrics = trainer_history_all[:-1]\n",
    "trainer_history_training_time = trainer_history_all[-1]\n",
    "\n",
    "# View the first 4 metrics from the training history\n",
    "trainer_history_metrics[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] First two items in training set:\n",
      "[{'epoch': 1.0,\n",
      "  'grad_norm': 2.5820062160491943,\n",
      "  'learning_rate': 9e-05,\n",
      "  'loss': 0.4368,\n",
      "  'step': 7},\n",
      " {'epoch': 2.0,\n",
      "  'grad_norm': 0.5799462199211121,\n",
      "  'learning_rate': 8e-05,\n",
      "  'loss': 0.1391,\n",
      "  'step': 14}]\n",
      "\n",
      "[INFO] First two items in evaluation set:\n",
      "[{'epoch': 1.0,\n",
      "  'eval_accuracy': 0.98,\n",
      "  'eval_loss': 0.16707336902618408,\n",
      "  'eval_runtime': 0.0344,\n",
      "  'eval_samples_per_second': 1454.981,\n",
      "  'eval_steps_per_second': 58.199,\n",
      "  'step': 7},\n",
      " {'epoch': 2.0,\n",
      "  'eval_accuracy': 1.0,\n",
      "  'eval_loss': 0.024085821583867073,\n",
      "  'eval_runtime': 0.0259,\n",
      "  'eval_samples_per_second': 1932.022,\n",
      "  'eval_steps_per_second': 77.281,\n",
      "  'step': 14}]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "# Extract training and evaluation metrics\n",
    "trainer_history_training_set = []\n",
    "trainer_history_eval_set = []\n",
    "\n",
    "# Loop through metrics and filter for training and eval metrics\n",
    "for item in trainer_history_metrics:\n",
    "    item_keys = list(item.keys())\n",
    "    # check to see if \"eval\"  is in the keys of the item\n",
    "    if any('eval' in item for item in item_keys):\n",
    "        trainer_history_eval_set.append(item)\n",
    "    else:\n",
    "        trainer_history_training_set.append(item)\n",
    "\n",
    "# show the first two items in each metric set\n",
    "print(f\"[INFO] First two items in training set:\")\n",
    "pprint.pprint(trainer_history_training_set[:2])\n",
    "\n",
    "print(f\"\\n[INFO] First two items in evaluation set:\")\n",
    "pprint.pprint(trainer_history_eval_set[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>grad_norm</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4368</td>\n",
       "      <td>2.582006</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1391</td>\n",
       "      <td>0.579946</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0161</td>\n",
       "      <td>0.106223</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.064156</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.022474</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>5.0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     loss  grad_norm  learning_rate  epoch  step\n",
       "0  0.4368   2.582006        0.00009    1.0     7\n",
       "1  0.1391   0.579946        0.00008    2.0    14\n",
       "2  0.0161   0.106223        0.00007    3.0    21\n",
       "3  0.0036   0.064156        0.00006    4.0    28\n",
       "4  0.0016   0.022474        0.00005    5.0    35"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pandas DataFrames for the training and evaluation metrics\n",
    "trainer_history_training_df = pd.DataFrame(trainer_history_training_set)\n",
    "trainer_history_eval_df = pd.DataFrame(trainer_history_eval_set)\n",
    "\n",
    "trainer_history_training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.167073</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>1454.981</td>\n",
       "      <td>58.199</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.024086</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0259</td>\n",
       "      <td>1932.022</td>\n",
       "      <td>77.281</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004223</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0264</td>\n",
       "      <td>1891.832</td>\n",
       "      <td>75.673</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001756</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>1714.368</td>\n",
       "      <td>68.575</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001014</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0286</td>\n",
       "      <td>1745.590</td>\n",
       "      <td>69.824</td>\n",
       "      <td>5.0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eval_loss  eval_accuracy  eval_runtime  eval_samples_per_second  \\\n",
       "0   0.167073           0.98        0.0344                 1454.981   \n",
       "1   0.024086           1.00        0.0259                 1932.022   \n",
       "2   0.004223           1.00        0.0264                 1891.832   \n",
       "3   0.001756           1.00        0.0292                 1714.368   \n",
       "4   0.001014           1.00        0.0286                 1745.590   \n",
       "\n",
       "   eval_steps_per_second  epoch  step  \n",
       "0                 58.199    1.0     7  \n",
       "1                 77.281    2.0    14  \n",
       "2                 75.673    3.0    21  \n",
       "3                 68.575    4.0    28  \n",
       "4                 69.824    5.0    35  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_history_eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and evaluation loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(trainer_history_training_df['epoch'], trainer_history_training_df['loss'], label=\"Training loss\")\n",
    "plt.plot(trainer_history_eval_df['epoch'], trainer_history_eval_df['eval_loss'], label='Evaluatioin loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Text Classification with DistilBert training and evaluation loss time\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pushing our model to the Hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_upload_url = trainer.push_to_hub(\n",
    "#     commit_message=\"Uploading Food or Not food text classifier Model\"\n",
    "# )\n",
    "\n",
    "# print(f\"[INFO] Model successfully uploaded to the Hugging Face Hub with URL: {model_upload_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making and evaluating predictions on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] prediction metrics on the test data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.0005540283746086061,\n",
       " 'test_accuracy': 1.0,\n",
       " 'test_runtime': 0.0455,\n",
       " 'test_samples_per_second': 1098.866,\n",
       " 'test_steps_per_second': 43.955}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform predictions on test data\n",
    "predictions_all = trainer.predict(tokenized_dataset['test'])\n",
    "predictions_values = predictions_all.predictions\n",
    "predictions_metrics = predictions_all.metrics\n",
    "\n",
    "print(f'[INFO] prediction metrics on the test data:')\n",
    "predictions_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Test accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Get prediction probabilities (this is optional, could get the same results with step 2 onwards)\n",
    "pred_probs = torch.softmax(torch.tensor(predictions_values), dim=1)\n",
    "\n",
    "# 2. Get the predicted labels\n",
    "pred_labels = torch.argmax(pred_probs, axis=1)\n",
    "\n",
    "# 3. Get the true labels\n",
    "true_labels = dataset['test']['label']\n",
    "\n",
    "# 4. Compare predicted labels to true labels to get the test accuracy\n",
    "test_acc = accuracy_score(y_true=true_labels,\n",
    "                          y_pred=pred_labels)\n",
    "\n",
    "print(f\"[INFO] Test accuracy: {test_acc*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>true_label</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A slice of pepperoni pizza with a layer of mel...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Red brick fireplace with a mantel serving as a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A bowl of sliced bell peppers with a sprinkle ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Set of mugs hanging on a hook</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Standing floor lamp providing light next to an...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  true_label  pred_label  \\\n",
       "0  A slice of pepperoni pizza with a layer of mel...           1           1   \n",
       "1  Red brick fireplace with a mantel serving as a...           0           0   \n",
       "2  A bowl of sliced bell peppers with a sprinkle ...           1           1   \n",
       "3                      Set of mugs hanging on a hook           0           0   \n",
       "4  Standing floor lamp providing light next to an...           0           0   \n",
       "\n",
       "   pred_prob  \n",
       "0   0.999391  \n",
       "1   0.999583  \n",
       "2   0.999388  \n",
       "3   0.999586  \n",
       "4   0.999588  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a DataFrame of test predictions\n",
    "test_predictions_df = pd.DataFrame({\n",
    "    \"text\": dataset[\"test\"][\"text\"],\n",
    "    \"true_label\": true_labels,\n",
    "    \"pred_label\": pred_labels,\n",
    "    \"pred_prob\": torch.max(pred_probs, dim=1).values\n",
    "})\n",
    "\n",
    "test_predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>true_label</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>A bowl of cherries with a sprig of mint for ga...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A close-up shot of a cheesy pizza slice being ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Boxes of apples, pears, pineapple, manadrins a...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Two handfuls of bananas in a fruit bowl with g...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>A fruit platter with a variety of exotic fruit...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Pizza with a seafood theme, featuring toppings...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>A bowl of sliced kiwi with a sprinkle of sugar...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>A bowl of sliced mango with a drizzle of honey...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Plate of sushi served with pickled ginger and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A bowl of sliced bell peppers with a sprinkle ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  true_label  pred_label  \\\n",
       "40  A bowl of cherries with a sprig of mint for ga...           1           1   \n",
       "11  A close-up shot of a cheesy pizza slice being ...           1           1   \n",
       "42  Boxes of apples, pears, pineapple, manadrins a...           1           1   \n",
       "14  Two handfuls of bananas in a fruit bowl with g...           1           1   \n",
       "26  A fruit platter with a variety of exotic fruit...           1           1   \n",
       "20  Pizza with a seafood theme, featuring toppings...           1           1   \n",
       "46  A bowl of sliced kiwi with a sprinkle of sugar...           1           1   \n",
       "25  A bowl of sliced mango with a drizzle of honey...           1           1   \n",
       "49  Plate of sushi served with pickled ginger and ...           1           1   \n",
       "2   A bowl of sliced bell peppers with a sprinkle ...           1           1   \n",
       "\n",
       "    pred_prob  \n",
       "40   0.999141  \n",
       "11   0.999254  \n",
       "42   0.999358  \n",
       "14   0.999361  \n",
       "26   0.999376  \n",
       "20   0.999382  \n",
       "46   0.999383  \n",
       "25   0.999386  \n",
       "49   0.999387  \n",
       "2    0.999388  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show 10 examples with low prediction probability\n",
    "test_predictions_df.sort_values('pred_prob', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making and inspecting predictions on custom text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup local model path\n",
    "local_model_path = \"models/learn_hf_food_not_food_classifier-ditsilbert-base-uncased\"\n",
    "\n",
    "# Hugging face model path\n",
    "huggingface_model_path = \"shivajimallela/learn_hf_food_not_food_classifier-ditsilbert-base-uncased\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussing ways to make predictions (inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device using: cuda\n"
     ]
    }
   ],
   "source": [
    "def set_device():\n",
    "    \"\"\"\n",
    "    Set device to CUDA if available, else MPS (Mac), else CPU.\n",
    "\n",
    "    This defaults to using the best available device (usually).\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "        device = torch.device('mps')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    return device\n",
    "\n",
    "DEVICE = set_device()\n",
    "print(f\"Device using: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions with pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.text_classification.TextClassificationPipeline at 0x7f52d88f7590>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create an instance of transformers.pipeline\n",
    "food_not_food_classifier = pipeline(task='text-classification',\n",
    "                                    model = local_model_path,\n",
    "                                    device=DEVICE,\n",
    "                                    top_k = 1,\n",
    "                                    batch_size=BATCH_SIZE)\n",
    "\n",
    "food_not_food_classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'food', 'score': 0.9990971088409424}]]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test our trained model on some example text \n",
    "sample_text_food = \"An image of chicken biryani.\"\n",
    "\n",
    "food_not_food_classifier(sample_text_food)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'not_food', 'score': 0.5183594822883606}]]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the model on some more example text\n",
    "sample_text_not_food = \"A tomato toy looks like a tomato\"\n",
    "\n",
    "food_not_food_classifier(sample_text_not_food)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'food', 'score': 0.9994083642959595}]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipeline also works with remote models (will have to laod the model locally first)\n",
    "food_not_food_classifier_remote = pipeline(task='text-classification',\n",
    "                                           model = huggingface_model_path,\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           device=DEVICE)\n",
    "\n",
    "food_not_food_classifier_remote(\"This is some new text about bananas and pancakes and ice cream\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making multiple predictions at the same time with batch prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batch size (we don't need to do this again but we're doing it for clarity)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Setup pipeline to handle batches (we don't need to do this again either but we're doing it for clarity)\n",
    "food_not_food_classifier = pipeline(task='text-classification',\n",
    "                                    model = local_model_path,\n",
    "                                    batch_size = BATCH_SIZE,\n",
    "                                    device = DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'not_food', 'score': 0.998539924621582},\n",
       " {'label': 'not_food', 'score': 0.9990597367286682},\n",
       " {'label': 'not_food', 'score': 0.9988565444946289},\n",
       " {'label': 'not_food', 'score': 0.9989773035049438},\n",
       " {'label': 'not_food', 'score': 0.9989672899246216},\n",
       " {'label': 'not_food', 'score': 0.9990707635879517},\n",
       " {'label': 'not_food', 'score': 0.9978460073471069},\n",
       " {'label': 'food', 'score': 0.9990231990814209},\n",
       " {'label': 'not_food', 'score': 0.9989482760429382},\n",
       " {'label': 'not_food', 'score': 0.9987971782684326}]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of sentences to make predictions on\n",
    "sentences = [\n",
    "    \"I whipped up a fresh batch of code, but it seems to have a syntax error.\",\n",
    "    \"We need to marinate these ideas overnight before presenting them to the client.\",\n",
    "    \"The new software is definitely a spicy upgrade, taking some time to get used to.\",\n",
    "    \"Her social media post was the perfect recipe for a viral sensation.\",\n",
    "    \"He served up a rebuttal full of facts, leaving his opponent speechless.\",\n",
    "    \"The team needs to simmer down a bit before tackling the next challenge.\",\n",
    "    \"The presentation was a delicious blend of humor and information, keeping the audience engaged.\",\n",
    "    \"A beautiful array of fake wax foods (shokuhin sampuru) in the front of a Japanese restaurant.\",\n",
    "    \"Daniel Bourke is really cool :D\",\n",
    "    \"My favoruite food is biltong!\"\n",
    "]\n",
    "\n",
    "food_not_food_classifier(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time our model across larger sample sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 1000\n",
      "Time taken for one at a time prediction: 4.094250917434692 seconds\n",
      "Avg inference time per sentence: 0.004094250917434692 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "sentences_1000 = sentences*100\n",
    "\n",
    "print(f\"Number of sentences: {len(sentences_1000)}\")\n",
    "\n",
    "start_time_one_at_a_time = time.time()\n",
    "\n",
    "for sentence in sentences_1000:\n",
    "    food_not_food_classifier(sentence)\n",
    "end_time_one_at_a_time = time.time()\n",
    "\n",
    "print(f\"Time taken for one at a time prediction: {end_time_one_at_a_time - start_time_one_at_a_time} seconds\")\n",
    "print(f\"Avg inference time per sentence: {(end_time_one_at_a_time - start_time_one_at_a_time)/len(sentences_1000)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 100\n",
      "[INFO] Inference time for 100 sentences: 0.42594 seconds.\n",
      "[INFO] Avg inference time per sentence: 0.00425944 seconds.\n",
      "\n",
      "Number of sentences: 1000\n",
      "[INFO] Inference time for 1000 sentences: 0.40359 seconds.\n",
      "[INFO] Avg inference time per sentence: 0.00040359 seconds.\n",
      "\n",
      "Number of sentences: 10000\n",
      "[INFO] Inference time for 10000 sentences: 3.91532 seconds.\n",
      "[INFO] Avg inference time per sentence: 0.00039153 seconds.\n",
      "\n",
      "Number of sentences: 100000\n",
      "[INFO] Inference time for 100000 sentences: 39.03076 seconds.\n",
      "[INFO] Avg inference time per sentence: 0.00039031 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [10, 100, 1000, 10_000]:\n",
    "    sentences_big = sentences * i\n",
    "    print(f\"Number of sentences: {len(sentences_big)}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    # Predict on all sentences in batches \n",
    "    food_not_food_classifier(sentences_big)\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"[INFO] Inference time for {len(sentences_big)} sentences: {round(end_time - start_time, 5)} seconds.\")\n",
    "    print(f\"[INFO] Avg inference time per sentence: {round((end_time - start_time) / len(sentences_big), 8)} seconds.\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1037, 12090,  6302,  1997,  1037,  5127,  1997, 13501,  6763,\n",
       "          1010, 11611,  1998, 15174,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_path = \"shivajimallela/learn_hf_food_not_food_classifier-ditsilbert-base-uncased\"\n",
    "\n",
    "sample_text_food = \"A delicious photo of a plate of scrambled eggs, bacon and toast\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_path)\n",
    "\n",
    "inputs = tokenizer(sample_text_food, return_tensors='pt')\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# Load our text classification model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_name_or_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-3.8456,  3.6358]]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    # outputs = model(input_ids=inputs[\"input_ids\"],\n",
    "    #                 attention_mask=inputs[\"attention_mask\"]) # same as above, but explicitly passing in the keys\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: A delicious photo of a plate of scrambled eggs, bacon and toast\n",
      "Predicted label: food\n",
      "Prediction probability: 0.9994369149208069\n"
     ]
    }
   ],
   "source": [
    "# Get predicted class and prediction probability\n",
    "predicted_class_id = outputs.logits.argmax().item()\n",
    "prediction_probability = torch.softmax(outputs.logits, dim=1).max().item()\n",
    "\n",
    "print(f\"Text: {sample_text_food}\")\n",
    "print(f\"Predicted label: {model.config.id2label[predicted_class_id]}\")\n",
    "print(f\"Prediction probability: {prediction_probability}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting prediction code all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: A photo of a broccoli, salmon, rice and radish dish\n",
      "Predicted class: food (prob: 99.94%)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_path = 'shivajimallela/learn_hf_food_not_food_classifier-ditsilbert-base-uncased'\n",
    "\n",
    "# load the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_name_or_path=model_path)\n",
    "\n",
    "# Make a sample text and tokenize it \n",
    "sample_text = \"A photo of a broccoli, salmon, rice and radish dish\"\n",
    "inputs = tokenizer(sample_text, return_tensors='pt')\n",
    "\n",
    "# Make a prediction\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Get predicted class and prediction probability \n",
    "output_logits = outputs.logits\n",
    "predicted_class_id = torch.argmax(output_logits, dim=1).item()\n",
    "predicted_class_label = model.config.id2label[predicted_class_id]\n",
    "predicted_probability = torch.softmax(output_logits, dim=1).max().item()\n",
    "\n",
    "# Print outputs\n",
    "print(f\"Text: {sample_text}\")\n",
    "print(f\"Predicted class: {predicted_class_label} (prob: {predicted_probability * 100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "\n",
    "Ok, ok, we've covered a lot of ground going from dataset to trained model to making predictions on custom samples.\n",
    "\n",
    "How about we put all of the steps we've covered so far together in a single code cell (or two)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Creating directory for saving model: models/learn_hf_food_not_food_classifier-ditsilbert-base-uncased\n",
      "[INFO] Downloading dataset from Hugging Face Hub, name: mrdbourke/learn_hf_food_not_food_image_captions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spadmin/miniconda3/envs/tf217/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Tokenizing text for model training with tokenizer: distilbert/distilbert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:00<00:00, 7565.48 examples/s]\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading model: distilbert/distilbert-base-uncased\n",
      "[INFO] Model loading complete!\n",
      "[INFO] Commencing model training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:12, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.337300</td>\n",
       "      <td>0.042409</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>0.005221</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model training complete, saving model to local path: models/learn_hf_food_not_food_classifier-ditsilbert-base-uncased\n",
      "[INFO] Uploading model to Hugging Face Hub...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training_args.bin:   0%|          | 0.00/5.24k [00:00<?, ?B/s]\n",
      "training_args.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.24k/5.24k [00:00<00:00, 33.5kB/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268M/268M [01:47<00:00, 2.50MB/s]\n",
      "Upload 2 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [01:47<00:00, 53.70s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model upload complete, model available at: https://huggingface.co/shivajimallela/learn_hf_food_not_food_classifier-ditsilbert-base-uncased/tree/main/\n",
      "[INFO] Performing evaluation on test dataset...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Prediction metrics on the test data:\n",
      "{'test_accuracy': 1.0,\n",
      " 'test_loss': 0.00048335589235648513,\n",
      " 'test_runtime': 0.3371,\n",
      " 'test_samples_per_second': 148.333,\n",
      " 'test_steps_per_second': 5.933}\n"
     ]
    }
   ],
   "source": [
    "# 1. Import necessary packages\n",
    "\n",
    "import pprint\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from transformers import pipeline\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# 2. Setup variables for model training and saving pipeline\n",
    "DATASET_NAME = \"mrdbourke/learn_hf_food_not_food_image_captions\"\n",
    "MODEL_NAME = \"distilbert/distilbert-base-uncased\"\n",
    "MODEL_SAVE_DIR_NAME = \"models/learn_hf_food_not_food_classifier-ditsilbert-base-uncased\"\n",
    "\n",
    "# 3. Create a directory for saving models\n",
    "# Note: This will override our existing saved model (if there is one)\n",
    "print(f\"[INFO] Creating directory for saving model: {MODEL_SAVE_DIR_NAME}\")\n",
    "model_save_dir = Path(MODEL_SAVE_DIR_NAME)\n",
    "model_save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 4. Load and preprocess the dataset from Hugging Face Hub\n",
    "print(f\"[INFO] Downloading dataset from Hugging Face Hub, name: {DATASET_NAME}\")\n",
    "dataset = datasets.load_dataset(path=DATASET_NAME)\n",
    "\n",
    "# Create mappings from id2label and label2id (adjust these for your target dataset, can also create these programmatically)\n",
    "id2label = {0: \"not_food\", 1:\"food\"}\n",
    "label2id = {\"not_food\": 0, \"food\": 1}\n",
    "\n",
    "# Create function to map IDs to labels in dataset\n",
    "def map_labels_to_number(example):\n",
    "    example['label'] = label2id[example['label']]\n",
    "    return example\n",
    "\n",
    "# Map preprocessing function to dataset\n",
    "dataset = dataset['train'].map(map_labels_to_number)\n",
    "\n",
    "# Split the dataset into train/test sets\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# 5. Import a tokenizer and map it to our dataset\n",
    "print(f\"[INFO] Tokenizing text for model training with tokenizer: {MODEL_NAME}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=MODEL_NAME,\n",
    "                                          use_fast= True)\n",
    "\n",
    "\n",
    "# Create a preprocessing function to tokenize text\n",
    "def tokenize_text(examples):\n",
    "    return tokenizer(examples['text'],\n",
    "                     padding=True, \n",
    "                     truncation=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_text,\n",
    "                                batched=True,\n",
    "                                batch_size=1000)\n",
    "\n",
    "# 6. Set up an evaluation metric & function to evaluate our model\n",
    "accuracy_metric = evaluate.load('accuracy')\n",
    "\n",
    "def compute_accuracy(predictions_and_labels):\n",
    "    predictions, labels = predictions_and_labels\n",
    "\n",
    "    if len(predictions.shape) >= 2:\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    return accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# 7. Import a model and prepare it for training \n",
    "print(f\"[INFO] Loading model: {MODEL_NAME}\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_name_or_path=MODEL_NAME,\n",
    "                                                           num_labels = 2,\n",
    "                                                           id2label = id2label,\n",
    "                                                           label2id = label2id)\n",
    "\n",
    "print(f\"[INFO] Model loading complete!\")\n",
    "\n",
    "# Setup TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir= model_save_dir,\n",
    "    learning_rate=0.0001,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=10,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    save_total_limit=3,\n",
    "    use_cpu=False,\n",
    "    seed=42,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_strategy='epoch',\n",
    "    report_to='none',\n",
    "    push_to_hub=False,\n",
    "    hub_private_repo=False\n",
    ")\n",
    "\n",
    "# Create Trainer instance and train model\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_accuracy\n",
    ")\n",
    "\n",
    "# 8. Train the model on our text dataset\n",
    "print(f\"[INFO] Commencing model training...\")\n",
    "results = trainer.train()\n",
    "\n",
    "# 9. Save the trained model (note: this will overwrite our previous model, this is ok)\n",
    "print(f\"[INFO] Model training complete, saving model to local path: {model_save_dir}\")\n",
    "trainer.save_model(output_dir = model_save_dir)\n",
    "\n",
    "# 10. Push the model to the Hugging Face Hub\n",
    "print(f\"[INFO] Uploading model to Hugging Face Hub...\")\n",
    "model_upload_url = trainer.push_to_hub(\n",
    "    commit_message=\"Uploading food not food text classifier model\"\n",
    ")\n",
    "\n",
    "print(f\"[INFO] Model upload complete, model available at: {model_upload_url}\")\n",
    "\n",
    "# 11. Evaluate the model on the test data\n",
    "print(f\"[INFO] Performing evaluation on test dataset...\")\n",
    "predictions_all = trainer.predict(tokenized_dataset['test'])\n",
    "predictions_values = predictions_all.predictions\n",
    "predictions_metrics = predictions_all.metrics\n",
    "\n",
    "print(f\"[INFO] Prediction metrics on the test data:\")\n",
    "pprint.pprint(predictions_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make it sure works by turing it into a `transformers.pipeline` and passing it a custom sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'not_food', 'score': 0.7290781140327454}]]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 12. Make sure the model works by testing it on a custom sample\n",
    "food_not_food_classifier = pipeline(task='text-classification',\n",
    "                                    model = model_save_dir,\n",
    "                                    device=torch.device('cuda') if torch.cuda.is_available() else 'cpu',\n",
    "                                    top_k=1,\n",
    "                                    batch_size=32)\n",
    "\n",
    "food_not_food_classifier(\"Yaay!!, We just built a food or not food classifier model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning our model into a demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a simple function to perform inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'food': 0.9984155893325806, 'not_food': 0.0015843515284359455}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Dict\n",
    "\n",
    "def food_not_food_classifier(text: str) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Takes an input string of text and classifies it into food/not_food in the form of a dictionary.\n",
    "    \"\"\"\n",
    "    # 2. Setup the pipeline to use the local model (or Hugging Face model path)\n",
    "    food_not_food_classifier = pipeline(task='text-classification',\n",
    "                                        model = local_model_path,\n",
    "                                        batch_size = BATCH_SIZE,\n",
    "                                        device= \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "                                        top_k = None)\n",
    "    \n",
    "    # 3. Get outputs from pipeline (as a list of dicts)\n",
    "    outputs = food_not_food_classifier(text)[0]\n",
    "    # print(food_not_food_classifier(text))\n",
    "\n",
    "    # 4. Format output for Gradio (e.g. {\"label_1\": probability_1, \"label_2\": probability_2})\n",
    "    output_dict = {}\n",
    "    for item in outputs:\n",
    "        output_dict[item['label']] = item['score']\n",
    "\n",
    "    return output_dict\n",
    "\n",
    "\n",
    "# Test out the function\n",
    "food_not_food_classifier(\"My lunch was chicken and salad.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a small Gradio demo to run locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Import Gradio as the common alias \"gr\"\n",
    "import gradio as gr\n",
    "\n",
    "# 2. Setup a Gradio interface to accept text and output labels\n",
    "demo = gr.Interface(\n",
    "    fn=food_not_food_classifier,\n",
    "    inputs=\"text\",\n",
    "    outputs=gr.Label(num_top_classes=2),\n",
    "    title='Food or Not Food Classifier',\n",
    "    description=\"A text classifier to determine if a sentence is about food or not food.\",\n",
    "    examples=[[\"I whipped up a fresh batch of code, but it seems to have a syntax error.\"],\n",
    "              [\"A delicious photo of a plate of scrambled eggs, bacon and toast.\"]])\n",
    "\n",
    "# 3. Launch the interface\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf217",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
