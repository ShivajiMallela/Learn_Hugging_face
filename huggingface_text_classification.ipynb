{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting .env\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What we're going to build\n",
    "\n",
    "We're going to be bulding a `food`/`not_food` **text classification model**. \n",
    "\n",
    "Given a piece of a text (such as an image caption), our model will be able to predict if it's about food or not.\n",
    "\n",
    "More specifically, we're going to follow the following steps:\n",
    "\n",
    "1. **[Data](https://huggingface.co/datasets/mrdbourke/learn_hf_food_not_food_image_captions): Problem defintion and dataset preparation** - Getting a dataset/setting up the problem space.\n",
    "2. **[Model](https://huggingface.co/mrdbourke/learn_hf_food_not_food_text_classifier-distilbert-base-uncased): Finding, training and evaluating a model** - Finding a text classification model suitable for our problem on Hugging Face and customizing it to our own dataset.\n",
    "3. **[Demo](https://huggingface.co/spaces/mrdbourke/learn_hf_food_not_food_text_classifier_demo): Creating a demo and put our model into the real world** - Sharing our trained model in a way others can access and use.\n",
    "\n",
    "By the end of this project, you'll have a trained model and [demo on Hugging Face](https://huggingface.co/spaces/mrdbourke/learn_hf_food_not_food_text_classifier_demo) you can share with others:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers version: 4.44.2\n",
      "Datasets version: 3.0.0\n",
      "Torch version: 2.4.1+cu121\n"
     ]
    }
   ],
   "source": [
    "# install dependencies\n",
    "try:\n",
    "    import datasets, evaluate, accelerate\n",
    "    import gradio as gr\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -U datasets, evaluate, accelerate, gradio\n",
    "    import datasets, evaluate, accelerate\n",
    "    import gradio as gr\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "print(f\"Transformers version: {transformers.__version__}\")\n",
    "print(f\"Datasets version: {datasets.__version__}\")\n",
    "print(f\"Torch version: {torch.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset from hugging face hub\n",
    "dataset = datasets.load_dataset(path=\"mrdbourke/learn_hf_food_not_food_image_captions\")\n",
    "\n",
    "# inspect the dataset\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['text', 'label']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what features are there\n",
    "dataset.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 250\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the training split\n",
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Creamy cauliflower curry with garlic naan, featuring tender cauliflower in a rich sauce with cream and spices, served with garlic naan bread.',\n",
       " 'label': 'food'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect random examples from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Random samples from dataset:\n",
      "\n",
      "Text: A gourmet pizza with a pesto base, topped with grilled chicken and sun-dried tomatoes | Label: food\n",
      "Text: A bowl of mixed berries, including blueberries, raspberries, and blackberries | Label: food\n",
      "Text: Yellow squash in a bowl, sprinkled with oregano and served with a side of pesto sauce for a tasty, flavorful dish. | Label: food\n",
      "Text: A square slice of Sicilian-style pizza with a thick and fluffy crust | Label: food\n",
      "Text: Hearty pumpkin curry with toasted pumpkin seeds, featuring sweet pumpkin pieces in a creamy coconut milk sauce, finished with toasted seeds. | Label: food\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random_indexes = random.sample(range(len(dataset['train'])), 5)\n",
    "random_samples  = dataset['train'][random_indexes]\n",
    "\n",
    "print(f\"[INFO] Random samples from dataset:\\n\")\n",
    "for item in zip(random_samples['text'], random_samples['label']):\n",
    "    print(f\"Text: {item[0]} | Label: {item[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['food', 'not_food']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unique label values\n",
    "dataset['train'].unique('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'food': 125, 'not_food': 125})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check number of each label\n",
    "from collections import Counter\n",
    "\n",
    "Counter(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Creamy cauliflower curry with garlic naan, fea...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Set of books stacked on a desk</td>\n",
       "      <td>not_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Watching TV together, a family has their dog s...</td>\n",
       "      <td>not_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wooden dresser with a mirror reflecting the room</td>\n",
       "      <td>not_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lawn mower stored in a shed</td>\n",
       "      <td>not_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Standing floor lamp providing light next to an...</td>\n",
       "      <td>not_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Luxurious coconut shrimp curry on a generous p...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Barbecue grill waiting on a patio</td>\n",
       "      <td>not_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Family gathered around a dining table, laughin...</td>\n",
       "      <td>not_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Taking a nap on a hammock, a man has his dog s...</td>\n",
       "      <td>not_food</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text     label\n",
       "0    Creamy cauliflower curry with garlic naan, fea...      food\n",
       "1                       Set of books stacked on a desk  not_food\n",
       "2    Watching TV together, a family has their dog s...  not_food\n",
       "3     Wooden dresser with a mirror reflecting the room  not_food\n",
       "4                          Lawn mower stored in a shed  not_food\n",
       "..                                                 ...       ...\n",
       "245  Standing floor lamp providing light next to an...  not_food\n",
       "246  Luxurious coconut shrimp curry on a generous p...      food\n",
       "247                  Barbecue grill waiting on a patio  not_food\n",
       "248  Family gathered around a dining table, laughin...  not_food\n",
       "249  Taking a nap on a hammock, a man has his dog s...  not_food\n",
       "\n",
       "[250 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn our dataset into a DataFrame and get a random sample\n",
    "food_not_food_df = pd.DataFrame(dataset['train'])\n",
    "food_not_food_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "food        125\n",
       "not_food    125\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the value counts of the label column\n",
    "food_not_food_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a mapping from labels to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 'not_food', '1': 'food'}\n",
      "{'not_food': '0', 'food': '1'}\n"
     ]
    }
   ],
   "source": [
    "# Create mapping from id2label and label2id\n",
    "id2label = {'0': 'not_food', '1' : 'food'}\n",
    "label2id = {'not_food' : '0', 'food' : '1'}\n",
    "\n",
    "print(id2label)\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID to Label mapping: {0: 'not_food', 1: 'food'}\n",
      "Label to ID mapping: {'not_food': 0, 'food': 1}\n"
     ]
    }
   ],
   "source": [
    "# Create mappings programmatically from dataset\n",
    "id2label = {idx: label for idx, label in enumerate(dataset['train'].unique('label')[::-1])}\n",
    "label2id = {label: idx for idx, label in id2label.items()}\n",
    "\n",
    "print(f\"ID to Label mapping: {id2label}\")\n",
    "print(f\"Label to ID mapping: {label2id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I love eating chicken.', 'label': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn labels into 0 or 1 (e.g. 0 for \"not_food\", 1 for \"food\")\n",
    "def map_labels_to_number(example):\n",
    "    example['label'] = label2id[example['label']]\n",
    "\n",
    "    return example\n",
    "\n",
    "example_sample = {\"text\": \"I love eating chicken.\", \"label\": \"food\"}\n",
    "\n",
    "# Test the function \n",
    "map_labels_to_number(example_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['Creamy cauliflower curry with garlic naan, featuring tender cauliflower in a rich sauce with cream and spices, served with garlic naan bread.',\n",
       "  'Set of books stacked on a desk',\n",
       "  'Watching TV together, a family has their dog stretched out on the floor',\n",
       "  'Wooden dresser with a mirror reflecting the room',\n",
       "  'Lawn mower stored in a shed'],\n",
       " 'label': [1, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map our dataset labels to numbers\n",
    "dataset = dataset[\"train\"].map(map_labels_to_number)\n",
    "dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['A bowl of sliced cucumbers with a sprinkle of dill and a side of sour cream',\n",
       "  'Black and white checkered kitchen floor adding a classic touch',\n",
       "  'A couple enjoying a movie night on the couch with their pets snuggled close',\n",
       "  'Black leather couch adding elegance to a living room',\n",
       "  'Remote control placed on a couch cushion'],\n",
       " 'label': [1, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle the dataset and view the first 5 samples (will return different results each time) \n",
    "dataset.shuffle()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Random sample from training dataset:\n",
      "Text: Camping tent pitched in a backyard\n",
      "Label: 0 (not_food)\n",
      "\n",
      "[INFO] Random sample from testing dataset:\n",
      "Text: Wooden dresser with a mirror reflecting the room\n",
      "Label: 0 (not_food)\n"
     ]
    }
   ],
   "source": [
    "random_idx_train = random.randint(0, len(dataset['train']))\n",
    "random_sample_train = dataset['train'][random_idx_train]\n",
    "\n",
    "random_idx_test = random.randint(0, len(dataset['test']))\n",
    "random_sample_test = dataset['test'][random_idx_test]\n",
    "\n",
    "print(f\"[INFO] Random sample from training dataset:\")\n",
    "print(f\"Text: {random_sample_train['text']}\\nLabel: {random_sample_train['label']} ({id2label[random_sample_train['label']]})\\n\")\n",
    "print(f\"[INFO] Random sample from testing dataset:\")\n",
    "print(f\"Text: {random_sample_test['text']}\\nLabel: {random_sample_test['label']} ({id2label[random_sample_test['label']]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spadmin/miniconda3/envs/tf217/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertTokenizerFast(name_or_path='distilbert/distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=\"distilbert/distilbert-base-uncased\",\n",
    "                                          use_fast = True)\n",
    "\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 2293, 10733, 102], 'attention_mask': [1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test out tokenizer\n",
    "tokenizer(\"I love pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 3698, 4083, 102], 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 30522\n",
      "Length of max tokenizer input sequence: 512\n"
     ]
    }
   ],
   "source": [
    "# Get the length of the vocabulary \n",
    "length_of_vocab = len(tokenizer.vocab)\n",
    "print(f\"Length of vocabulary is {length_of_vocab}\")\n",
    "\n",
    "# Get the maximum sequence length the tokenizer can handle\n",
    "max_tokenizer_input_seq = tokenizer.model_max_length\n",
    "print(f\"Length of max tokenizer input sequence: {max_tokenizer_input_seq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7975"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab['chicken']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets error because this word is not in the vocab\n",
    "# tokenizer.vocab['shivaji']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when calling the tokenizer on the word, it will automatically split the word into word pieces or subwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'shiva', '##ji', '[SEP]']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can check what word pieces got broken into with tokenizer.convert_ids_to_tokens(input_ids).\n",
    "tokenizer.convert_ids_to_tokens(tokenizer('shivaji').input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', '[UNK]', '[SEP]']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try to tokenize an emoji\n",
    "tokenizer.convert_ids_to_tokens(tokenizer(\"🏏\").input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the tokenizer.vocab is a Python dictionary, we can get a sample of the vocabulary using tokenizer.vocab.items()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('!', 999), ('\"', 1000), ('#', 1001), ('##!', 29612), ('##\"', 29613)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the first 5 items in the tokenizer vocab\n",
    "sorted(tokenizer.vocab.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bust', 13950),\n",
       " ('##open', 26915),\n",
       " ('memorials', 22899),\n",
       " ('mani', 23624),\n",
       " ('negotiations', 7776)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.sample(sorted(tokenizer.vocab.items()), k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a preprocessing function to tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(examples):\n",
    "    return tokenizer(examples['text'],\n",
    "                     padding=True,\n",
    "                     truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 2293, 7975, 102], 'attention_mask': [1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_sample_2 = {'text':\"I love chicken\", \"label\":1}\n",
    "\n",
    "tokenize_text(example_sample_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 50\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(function=tokenize_text,\n",
    "                                batched=True,\n",
    "                                batch_size=1000)\n",
    "\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Key: text\n",
      "Train sample: Set of headphones placed on a desk\n",
      "Test sample: A slice of pepperoni pizza with a layer of melted cheese\n",
      "\n",
      "[INFO] Key: label\n",
      "Train sample: 0\n",
      "Test sample: 1\n",
      "\n",
      "[INFO] Key: input_ids\n",
      "Train sample: [101, 2275, 1997, 2132, 19093, 2872, 2006, 1037, 4624, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Test sample: [101, 1037, 14704, 1997, 11565, 10698, 10733, 2007, 1037, 6741, 1997, 12501, 8808, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "[INFO] Key: attention_mask\n",
      "Train sample: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Test sample: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get two samples from the tokenized dataset\n",
    "train_tokenized_sample = tokenized_dataset['train'][0]\n",
    "test_tokenized_sample = tokenized_dataset[\"test\"][0]\n",
    "\n",
    "for key in train_tokenized_sample.keys():\n",
    "    print(f\"[INFO] Key: {key}\")\n",
    "    print(f\"Train sample: {train_tokenized_sample[key]}\")\n",
    "    print(f\"Test sample: {test_tokenized_sample[key]}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up an evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "accuracy_metric = evaluate.load('accuracy')\n",
    "\n",
    "def compute_accuracy(predictions_and_labels: Tuple[np.array, np.array]):\n",
    "    predictions, labels = predictions_and_labels\n",
    "\n",
    "    if len(predictions.shape)>=2:\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    return accuracy_metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy when all predictions are correct: {'accuracy': 1.0}\n",
      "Accuracy when one prediction is wrong: {'accuracy': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# Create example list of predictions and labels\n",
    "example_labels = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "example_predictions_all_correct = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "example_predictions_one_wrong = np.array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n",
    "\n",
    "# Test the function\n",
    "print(f\"Accuracy when all predictions are correct: {compute_accuracy((example_predictions_all_correct, example_labels))}\")\n",
    "print(f\"Accuracy when one prediction is wrong: {compute_accuracy((example_predictions_one_wrong, example_labels))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id2label: {0: 'not_food', 1: 'food'}\n",
      "label2id: {'not_food': 0, 'food': 1}\n"
     ]
    }
   ],
   "source": [
    "# Get id and label mappings\n",
    "print(f\"id2label: {id2label}\")\n",
    "print(f\"label2id: {label2id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"distilbert/distilbert-base-uncased\",\n",
    "    num_labels = 2,\n",
    "    id2label = id2label,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try and make a prediction with the loaded model (this will error)\n",
    "# model(**tokenized_dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the model\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting the parameters of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trainable_parameters': 66955010, 'total_parameters': 66955010}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_params(model):\n",
    "    trainable_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total_parameters = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "    return {\"trainable_parameters\": trainable_parameters, \"total_parameters\": total_parameters}\n",
    "\n",
    "# Count the parameters of the model\n",
    "count_params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a directory for saving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('models/learn_hf_food_not_food_classifier-ditsilbert-base-uncased')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create model output directory\n",
    "from pathlib import Path\n",
    "\n",
    "# Create models directory\n",
    "models_dir = Path(\"models\")\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Create model save name\n",
    "model_save_name = \"learn_hf_food_not_food_classifier-ditsilbert-base-uncased\"\n",
    "\n",
    "# create model save path\n",
    "model_save_dir = Path(models_dir, model_save_name)\n",
    "\n",
    "model_save_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up training arguments with TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving model checkpoints to: models/learn_hf_food_not_food_classifier-ditsilbert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "print(f\"[INFO] Saving model checkpoints to: {model_save_dir}\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_save_dir,\n",
    "    learning_rate=0.0001,\n",
    "    per_device_train_batch_size= 32,\n",
    "    per_device_eval_batch_size= 32,\n",
    "    num_train_epochs=10,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    save_total_limit=3,\n",
    "    use_cpu=False,\n",
    "    seed=42,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_strategy='epoch',\n",
    "    report_to='none',\n",
    "    # push_to_hub=True,\n",
    "    # hub_token=\"Token_here\",\n",
    "    hub_private_repo=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "_n_gpu=1,\n",
       "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
       "adafactor=False,\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "auto_find_batch_size=False,\n",
       "batch_eval_metrics=False,\n",
       "bf16=False,\n",
       "bf16_full_eval=False,\n",
       "data_seed=None,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=0,\n",
       "dataloader_persistent_workers=False,\n",
       "dataloader_pin_memory=True,\n",
       "dataloader_prefetch_factor=None,\n",
       "ddp_backend=None,\n",
       "ddp_broadcast_buffers=None,\n",
       "ddp_bucket_cap_mb=None,\n",
       "ddp_find_unused_parameters=None,\n",
       "ddp_timeout=1800,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=False,\n",
       "dispatch_batches=None,\n",
       "do_eval=True,\n",
       "do_predict=False,\n",
       "do_train=False,\n",
       "eval_accumulation_steps=None,\n",
       "eval_delay=0,\n",
       "eval_do_concat_batches=True,\n",
       "eval_on_start=False,\n",
       "eval_steps=None,\n",
       "eval_strategy=IntervalStrategy.EPOCH,\n",
       "eval_use_gather_object=False,\n",
       "evaluation_strategy=None,\n",
       "fp16=False,\n",
       "fp16_backend=auto,\n",
       "fp16_full_eval=False,\n",
       "fp16_opt_level=O1,\n",
       "fsdp=[],\n",
       "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
       "fsdp_min_num_params=0,\n",
       "fsdp_transformer_layer_cls_to_wrap=None,\n",
       "full_determinism=False,\n",
       "gradient_accumulation_steps=1,\n",
       "gradient_checkpointing=False,\n",
       "gradient_checkpointing_kwargs=None,\n",
       "greater_is_better=False,\n",
       "group_by_length=False,\n",
       "half_precision_backend=auto,\n",
       "hub_always_push=False,\n",
       "hub_model_id=None,\n",
       "hub_private_repo=False,\n",
       "hub_strategy=HubStrategy.EVERY_SAVE,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "include_inputs_for_metrics=False,\n",
       "include_num_input_tokens_seen=False,\n",
       "include_tokens_per_second=False,\n",
       "jit_mode_eval=False,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=0.0001,\n",
       "length_column_name=length,\n",
       "load_best_model_at_end=True,\n",
       "local_rank=0,\n",
       "log_level=passive,\n",
       "log_level_replica=warning,\n",
       "log_on_each_node=True,\n",
       "logging_dir=models/learn_hf_food_not_food_classifier-ditsilbert-base-uncased/runs/Nov20_10-32-23_Smalle3-Ai-L,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=500,\n",
       "logging_strategy=IntervalStrategy.EPOCH,\n",
       "lr_scheduler_kwargs={},\n",
       "lr_scheduler_type=SchedulerType.LINEAR,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=-1,\n",
       "metric_for_best_model=loss,\n",
       "mp_parameters=,\n",
       "neftune_noise_alpha=None,\n",
       "no_cuda=False,\n",
       "num_train_epochs=10,\n",
       "optim=OptimizerNames.ADAMW_TORCH,\n",
       "optim_args=None,\n",
       "optim_target_modules=None,\n",
       "output_dir=models/learn_hf_food_not_food_classifier-ditsilbert-base-uncased,\n",
       "overwrite_output_dir=False,\n",
       "past_index=-1,\n",
       "per_device_eval_batch_size=32,\n",
       "per_device_train_batch_size=32,\n",
       "prediction_loss_only=False,\n",
       "push_to_hub=False,\n",
       "push_to_hub_model_id=None,\n",
       "push_to_hub_organization=None,\n",
       "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
       "ray_scope=last,\n",
       "remove_unused_columns=True,\n",
       "report_to=[],\n",
       "restore_callback_states_from_checkpoint=False,\n",
       "resume_from_checkpoint=None,\n",
       "run_name=models/learn_hf_food_not_food_classifier-ditsilbert-base-uncased,\n",
       "save_on_each_node=False,\n",
       "save_only_model=False,\n",
       "save_safetensors=True,\n",
       "save_steps=500,\n",
       "save_strategy=IntervalStrategy.EPOCH,\n",
       "save_total_limit=3,\n",
       "seed=42,\n",
       "skip_memory_metrics=True,\n",
       "split_batches=None,\n",
       "tf32=None,\n",
       "torch_compile=False,\n",
       "torch_compile_backend=None,\n",
       "torch_compile_mode=None,\n",
       "torch_empty_cache_steps=None,\n",
       "torchdynamo=None,\n",
       "tpu_metrics_debug=False,\n",
       "tpu_num_cores=None,\n",
       "use_cpu=False,\n",
       "use_ipex=False,\n",
       "use_legacy_prediction_loop=False,\n",
       "use_mps_device=False,\n",
       "warmup_ratio=0.0,\n",
       "warmup_steps=0,\n",
       "weight_decay=0.0,\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up an instance of Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "# setup trainer\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['test'],\n",
    "    tokenizer = tokenizer,\n",
    "    compute_metrics=compute_accuracy\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training our text classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:11, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.338900</td>\n",
       "      <td>0.038924</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>0.005180</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.001986</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.001150</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train a text classification model\n",
    "results = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_runtime: 12.1419\n",
      "train_samples_per_second: 164.718\n",
      "train_steps_per_second: 5.765\n",
      "total_flos: 18110777160000.0\n",
      "train_loss: 0.036956672902618136\n",
      "epoch: 10.0\n"
     ]
    }
   ],
   "source": [
    "# Inspect training metrics\n",
    "for key, value in results.metrics.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving model to models/learn_hf_food_not_food_classifier-ditsilbert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "### Save the model for later use\n",
    "\n",
    "print(f\"[INFO] Saving model to {model_save_dir}\")\n",
    "trainer.save_model(output_dir=model_save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the model training metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 0.3389,\n",
       "  'grad_norm': 1.0947794914245605,\n",
       "  'learning_rate': 9e-05,\n",
       "  'epoch': 1.0,\n",
       "  'step': 7},\n",
       " {'eval_loss': 0.03892406076192856,\n",
       "  'eval_accuracy': 1.0,\n",
       "  'eval_runtime': 0.0295,\n",
       "  'eval_samples_per_second': 1692.945,\n",
       "  'eval_steps_per_second': 67.718,\n",
       "  'epoch': 1.0,\n",
       "  'step': 7},\n",
       " {'loss': 0.0203,\n",
       "  'grad_norm': 0.11125889420509338,\n",
       "  'learning_rate': 8e-05,\n",
       "  'epoch': 2.0,\n",
       "  'step': 14},\n",
       " {'eval_loss': 0.005179792642593384,\n",
       "  'eval_accuracy': 1.0,\n",
       "  'eval_runtime': 0.0282,\n",
       "  'eval_samples_per_second': 1773.19,\n",
       "  'eval_steps_per_second': 70.928,\n",
       "  'epoch': 2.0,\n",
       "  'step': 14},\n",
       " {'loss': 0.0039,\n",
       "  'grad_norm': 0.04140981286764145,\n",
       "  'learning_rate': 7e-05,\n",
       "  'epoch': 3.0,\n",
       "  'step': 21},\n",
       " {'eval_loss': 0.0019861687906086445,\n",
       "  'eval_accuracy': 1.0,\n",
       "  'eval_runtime': 0.0279,\n",
       "  'eval_samples_per_second': 1791.473,\n",
       "  'eval_steps_per_second': 71.659,\n",
       "  'epoch': 3.0,\n",
       "  'step': 21},\n",
       " {'loss': 0.0018,\n",
       "  'grad_norm': 0.025118859484791756,\n",
       "  'learning_rate': 6e-05,\n",
       "  'epoch': 4.0,\n",
       "  'step': 28},\n",
       " {'eval_loss': 0.0011495408834889531,\n",
       "  'eval_accuracy': 1.0,\n",
       "  'eval_runtime': 0.0273,\n",
       "  'eval_samples_per_second': 1828.555,\n",
       "  'eval_steps_per_second': 73.142,\n",
       "  'epoch': 4.0,\n",
       "  'step': 28},\n",
       " {'loss': 0.0012,\n",
       "  'grad_norm': 0.01712549291551113,\n",
       "  'learning_rate': 5e-05,\n",
       "  'epoch': 5.0,\n",
       "  'step': 35},\n",
       " {'eval_loss': 0.0008243808406405151,\n",
       "  'eval_accuracy': 1.0,\n",
       "  'eval_runtime': 0.0292,\n",
       "  'eval_samples_per_second': 1710.118,\n",
       "  'eval_steps_per_second': 68.405,\n",
       "  'epoch': 5.0,\n",
       "  'step': 35},\n",
       " {'loss': 0.0009,\n",
       "  'grad_norm': 0.012159767560660839,\n",
       "  'learning_rate': 4e-05,\n",
       "  'epoch': 6.0,\n",
       "  'step': 42},\n",
       " {'eval_loss': 0.0006737314979545772,\n",
       "  'eval_accuracy': 1.0,\n",
       "  'eval_runtime': 0.0271,\n",
       "  'eval_samples_per_second': 1847.89,\n",
       "  'eval_steps_per_second': 73.916,\n",
       "  'epoch': 6.0,\n",
       "  'step': 42},\n",
       " {'loss': 0.0007,\n",
       "  'grad_norm': 0.010188115760684013,\n",
       "  'learning_rate': 3e-05,\n",
       "  'epoch': 7.0,\n",
       "  'step': 49},\n",
       " {'eval_loss': 0.0005940592964179814,\n",
       "  'eval_accuracy': 1.0,\n",
       "  'eval_runtime': 0.0302,\n",
       "  'eval_samples_per_second': 1656.675,\n",
       "  'eval_steps_per_second': 66.267,\n",
       "  'epoch': 7.0,\n",
       "  'step': 49},\n",
       " {'loss': 0.0007,\n",
       "  'grad_norm': 0.01408334355801344,\n",
       "  'learning_rate': 2e-05,\n",
       "  'epoch': 8.0,\n",
       "  'step': 56},\n",
       " {'eval_loss': 0.0005508526228368282,\n",
       "  'eval_accuracy': 1.0,\n",
       "  'eval_runtime': 0.0258,\n",
       "  'eval_samples_per_second': 1934.392,\n",
       "  'eval_steps_per_second': 77.376,\n",
       "  'epoch': 8.0,\n",
       "  'step': 56},\n",
       " {'loss': 0.0006,\n",
       "  'grad_norm': 0.01050305925309658,\n",
       "  'learning_rate': 1e-05,\n",
       "  'epoch': 9.0,\n",
       "  'step': 63},\n",
       " {'eval_loss': 0.0005277534364722669,\n",
       "  'eval_accuracy': 1.0,\n",
       "  'eval_runtime': 0.0272,\n",
       "  'eval_samples_per_second': 1838.559,\n",
       "  'eval_steps_per_second': 73.542,\n",
       "  'epoch': 9.0,\n",
       "  'step': 63},\n",
       " {'loss': 0.0006,\n",
       "  'grad_norm': 0.010993443429470062,\n",
       "  'learning_rate': 0.0,\n",
       "  'epoch': 10.0,\n",
       "  'step': 70},\n",
       " {'eval_loss': 0.0005201687454245985,\n",
       "  'eval_accuracy': 1.0,\n",
       "  'eval_runtime': 0.0257,\n",
       "  'eval_samples_per_second': 1945.789,\n",
       "  'eval_steps_per_second': 77.832,\n",
       "  'epoch': 10.0,\n",
       "  'step': 70},\n",
       " {'train_runtime': 12.1419,\n",
       "  'train_samples_per_second': 164.718,\n",
       "  'train_steps_per_second': 5.765,\n",
       "  'total_flos': 18110777160000.0,\n",
       "  'train_loss': 0.036956672902618136,\n",
       "  'epoch': 10.0,\n",
       "  'step': 70}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.state.log_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 0.3389,\n",
       "  'grad_norm': 1.0947794914245605,\n",
       "  'learning_rate': 9e-05,\n",
       "  'epoch': 1.0,\n",
       "  'step': 7},\n",
       " {'eval_loss': 0.03892406076192856,\n",
       "  'eval_accuracy': 1.0,\n",
       "  'eval_runtime': 0.0295,\n",
       "  'eval_samples_per_second': 1692.945,\n",
       "  'eval_steps_per_second': 67.718,\n",
       "  'epoch': 1.0,\n",
       "  'step': 7},\n",
       " {'loss': 0.0203,\n",
       "  'grad_norm': 0.11125889420509338,\n",
       "  'learning_rate': 8e-05,\n",
       "  'epoch': 2.0,\n",
       "  'step': 14},\n",
       " {'eval_loss': 0.005179792642593384,\n",
       "  'eval_accuracy': 1.0,\n",
       "  'eval_runtime': 0.0282,\n",
       "  'eval_samples_per_second': 1773.19,\n",
       "  'eval_steps_per_second': 70.928,\n",
       "  'epoch': 2.0,\n",
       "  'step': 14}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get training history\n",
    "trainer_history_all = trainer.state.log_history\n",
    "trainer_history_metrics = trainer_history_all[:-1]\n",
    "trainer_history_training_time = trainer_history_all[-1]\n",
    "\n",
    "# View the first 4 metrics from the training history\n",
    "trainer_history_metrics[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] First two items in training set:\n",
      "[{'epoch': 1.0,\n",
      "  'grad_norm': 1.0947794914245605,\n",
      "  'learning_rate': 9e-05,\n",
      "  'loss': 0.3389,\n",
      "  'step': 7},\n",
      " {'epoch': 2.0,\n",
      "  'grad_norm': 0.11125889420509338,\n",
      "  'learning_rate': 8e-05,\n",
      "  'loss': 0.0203,\n",
      "  'step': 14}]\n",
      "\n",
      "[INFO] First two items in evaluation set:\n",
      "[{'epoch': 1.0,\n",
      "  'eval_accuracy': 1.0,\n",
      "  'eval_loss': 0.03892406076192856,\n",
      "  'eval_runtime': 0.0295,\n",
      "  'eval_samples_per_second': 1692.945,\n",
      "  'eval_steps_per_second': 67.718,\n",
      "  'step': 7},\n",
      " {'epoch': 2.0,\n",
      "  'eval_accuracy': 1.0,\n",
      "  'eval_loss': 0.005179792642593384,\n",
      "  'eval_runtime': 0.0282,\n",
      "  'eval_samples_per_second': 1773.19,\n",
      "  'eval_steps_per_second': 70.928,\n",
      "  'step': 14}]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "# Extract training and evaluation metrics\n",
    "trainer_history_training_set = []\n",
    "trainer_history_eval_set = []\n",
    "\n",
    "# Loop through metrics and filter for training and eval metrics\n",
    "for item in trainer_history_metrics:\n",
    "    item_keys = list(item.keys())\n",
    "    # check to see if \"eval\"  is in the keys of the item\n",
    "    if any('eval' in item for item in item_keys):\n",
    "        trainer_history_eval_set.append(item)\n",
    "    else:\n",
    "        trainer_history_training_set.append(item)\n",
    "\n",
    "# show the first two items in each metric set\n",
    "print(f\"[INFO] First two items in training set:\")\n",
    "pprint.pprint(trainer_history_training_set[:2])\n",
    "\n",
    "print(f\"\\n[INFO] First two items in evaluation set:\")\n",
    "pprint.pprint(trainer_history_eval_set[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>grad_norm</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3389</td>\n",
       "      <td>1.094779</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.111259</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.041410</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.025119</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.017125</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>5.0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     loss  grad_norm  learning_rate  epoch  step\n",
       "0  0.3389   1.094779        0.00009    1.0     7\n",
       "1  0.0203   0.111259        0.00008    2.0    14\n",
       "2  0.0039   0.041410        0.00007    3.0    21\n",
       "3  0.0018   0.025119        0.00006    4.0    28\n",
       "4  0.0012   0.017125        0.00005    5.0    35"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pandas DataFrames for the training and evaluation metrics\n",
    "trainer_history_training_df = pd.DataFrame(trainer_history_training_set)\n",
    "trainer_history_eval_df = pd.DataFrame(trainer_history_eval_set)\n",
    "\n",
    "trainer_history_training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038924</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>1692.945</td>\n",
       "      <td>67.718</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005180</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>1773.190</td>\n",
       "      <td>70.928</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001986</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>1791.473</td>\n",
       "      <td>71.659</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001150</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0273</td>\n",
       "      <td>1828.555</td>\n",
       "      <td>73.142</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000824</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>1710.118</td>\n",
       "      <td>68.405</td>\n",
       "      <td>5.0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eval_loss  eval_accuracy  eval_runtime  eval_samples_per_second  \\\n",
       "0   0.038924            1.0        0.0295                 1692.945   \n",
       "1   0.005180            1.0        0.0282                 1773.190   \n",
       "2   0.001986            1.0        0.0279                 1791.473   \n",
       "3   0.001150            1.0        0.0273                 1828.555   \n",
       "4   0.000824            1.0        0.0292                 1710.118   \n",
       "\n",
       "   eval_steps_per_second  epoch  step  \n",
       "0                 67.718    1.0     7  \n",
       "1                 70.928    2.0    14  \n",
       "2                 71.659    3.0    21  \n",
       "3                 73.142    4.0    28  \n",
       "4                 68.405    5.0    35  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_history_eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and evaluation loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(trainer_history_training_df['epoch'], trainer_history_training_df['loss'], label=\"Training loss\")\n",
    "plt.plot(trainer_history_eval_df['epoch'], trainer_history_eval_df['eval_loss'], label='Evaluatioin loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Text Classification with DistilBert training and evaluation loss time\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pushing our model to the Hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_upload_url = trainer.push_to_hub(\n",
    "#     commit_message=\"Uploading Food or Not food text classifier Model\"\n",
    "# )\n",
    "\n",
    "# print(f\"[INFO] Model successfully uploaded to the Hugging Face Hub with URL: {model_upload_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making and evaluating predictions on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] prediction metrics on the test data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.0005201687454245985,\n",
       " 'test_accuracy': 1.0,\n",
       " 'test_runtime': 0.0322,\n",
       " 'test_samples_per_second': 1554.655,\n",
       " 'test_steps_per_second': 62.186}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform predictions on test data\n",
    "predictions_all = trainer.predict(tokenized_dataset['test'])\n",
    "predictions_values = predictions_all.predictions\n",
    "predictions_metrics = predictions_all.metrics\n",
    "\n",
    "print(f'[INFO] prediction metrics on the test data:')\n",
    "predictions_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Test accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Get prediction probabilities (this is optional, could get the same results with step 2 onwards)\n",
    "pred_probs = torch.softmax(torch.tensor(predictions_values), dim=1)\n",
    "\n",
    "# 2. Get the predicted labels\n",
    "pred_labels = torch.argmax(pred_probs, axis=1)\n",
    "\n",
    "# 3. Get the true labels\n",
    "true_labels = dataset['test']['label']\n",
    "\n",
    "# 4. Compare predicted labels to true labels to get the test accuracy\n",
    "test_acc = accuracy_score(y_true=true_labels,\n",
    "                          y_pred=pred_labels)\n",
    "\n",
    "print(f\"[INFO] Test accuracy: {test_acc*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>true_label</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A slice of pepperoni pizza with a layer of mel...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Red brick fireplace with a mantel serving as a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A bowl of sliced bell peppers with a sprinkle ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Set of mugs hanging on a hook</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Standing floor lamp providing light next to an...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  true_label  pred_label  \\\n",
       "0  A slice of pepperoni pizza with a layer of mel...           1           1   \n",
       "1  Red brick fireplace with a mantel serving as a...           0           0   \n",
       "2  A bowl of sliced bell peppers with a sprinkle ...           1           1   \n",
       "3                      Set of mugs hanging on a hook           0           0   \n",
       "4  Standing floor lamp providing light next to an...           0           0   \n",
       "\n",
       "   pred_prob  \n",
       "0   0.999414  \n",
       "1   0.999602  \n",
       "2   0.999421  \n",
       "3   0.999614  \n",
       "4   0.999607  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a DataFrame of test predictions\n",
    "test_predictions_df = pd.DataFrame({\n",
    "    \"text\": dataset[\"test\"][\"text\"],\n",
    "    \"true_label\": true_labels,\n",
    "    \"pred_label\": pred_labels,\n",
    "    \"pred_prob\": torch.max(pred_probs, dim=1).values\n",
    "})\n",
    "\n",
    "test_predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>true_label</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>A bowl of cherries with a sprig of mint for ga...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A close-up shot of a cheesy pizza slice being ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Boxes of apples, pears, pineapple, manadrins a...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Two handfuls of bananas in a fruit bowl with g...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>A fruit platter with a variety of exotic fruit...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A slice of pepperoni pizza with a layer of mel...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>A bowl of sliced kiwi with a sprinkle of sugar...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>A bowl of sliced mango with a drizzle of honey...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>A bowl of sliced bananas with a sprinkle of co...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cherry tomatoes and mozzarella balls in a bowl...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  true_label  pred_label  \\\n",
       "40  A bowl of cherries with a sprig of mint for ga...           1           1   \n",
       "11  A close-up shot of a cheesy pizza slice being ...           1           1   \n",
       "42  Boxes of apples, pears, pineapple, manadrins a...           1           1   \n",
       "14  Two handfuls of bananas in a fruit bowl with g...           1           1   \n",
       "26  A fruit platter with a variety of exotic fruit...           1           1   \n",
       "0   A slice of pepperoni pizza with a layer of mel...           1           1   \n",
       "46  A bowl of sliced kiwi with a sprinkle of sugar...           1           1   \n",
       "25  A bowl of sliced mango with a drizzle of honey...           1           1   \n",
       "28  A bowl of sliced bananas with a sprinkle of co...           1           1   \n",
       "9   Cherry tomatoes and mozzarella balls in a bowl...           1           1   \n",
       "\n",
       "    pred_prob  \n",
       "40   0.999348  \n",
       "11   0.999376  \n",
       "42   0.999411  \n",
       "14   0.999412  \n",
       "26   0.999413  \n",
       "0    0.999414  \n",
       "46   0.999415  \n",
       "25   0.999416  \n",
       "28   0.999417  \n",
       "9    0.999417  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show 10 examples with low prediction probability\n",
    "test_predictions_df.sort_values('pred_prob', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making and inspecting predictions on custom text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup local model path\n",
    "local_model_path = \"models/learn_hf_food_not_food_classifier-ditsilbert-base-uncased\"\n",
    "\n",
    "# Hugging face model path\n",
    "huggingface_model_path = \"shivajimallela/learn_hf_food_not_food_classifier-ditsilbert-base-uncased\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussing ways to make predictions (inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device using: cuda\n"
     ]
    }
   ],
   "source": [
    "def set_device():\n",
    "    \"\"\"\n",
    "    Set device to CUDA if available, else MPS (Mac), else CPU.\n",
    "\n",
    "    This defaults to using the best available device (usually).\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "        device = torch.device('mps')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    return device\n",
    "\n",
    "DEVICE = set_device()\n",
    "print(f\"Device using: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions with pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.text_classification.TextClassificationPipeline at 0x7f3e526f4710>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create an instance of transformers.pipeline\n",
    "food_not_food_classifier = pipeline(task='text-classification',\n",
    "                                    model = local_model_path,\n",
    "                                    device=DEVICE,\n",
    "                                    top_k = 1,\n",
    "                                    batch_size=BATCH_SIZE)\n",
    "\n",
    "food_not_food_classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'food', 'score': 0.9992678761482239}]]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test our trained model on some example text \n",
    "sample_text_food = \"An image of chicken biryani.\"\n",
    "\n",
    "food_not_food_classifier(sample_text_food)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'food', 'score': 0.99791020154953}]]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the model on some more example text\n",
    "sample_text_not_food = \"A tomato toy looks like a tomato\"\n",
    "\n",
    "food_not_food_classifier(sample_text_not_food)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'food', 'score': 0.9993926286697388}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipeline also works with remote models (will have to laod the model locally first)\n",
    "food_not_food_classifier_remote = pipeline(task='text-classification',\n",
    "                                           model = huggingface_model_path,\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           device=DEVICE)\n",
    "\n",
    "food_not_food_classifier_remote(\"This is some new text about bananas and pancakes and ice cream\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making multiple predictions at the same time with batch prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batch size (we don't need to do this again but we're doing it for clarity)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Setup pipeline to handle batches (we don't need to do this again either but we're doing it for clarity)\n",
    "food_not_food_classifier = pipeline(task='text-classification',\n",
    "                                    model = local_model_path,\n",
    "                                    batch_size = BATCH_SIZE,\n",
    "                                    device = DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'not_food', 'score': 0.9883651733398438},\n",
       " {'label': 'not_food', 'score': 0.9982072114944458},\n",
       " {'label': 'not_food', 'score': 0.9953621029853821},\n",
       " {'label': 'not_food', 'score': 0.9984801411628723},\n",
       " {'label': 'not_food', 'score': 0.9963819980621338},\n",
       " {'label': 'not_food', 'score': 0.9985091090202332},\n",
       " {'label': 'not_food', 'score': 0.9879025816917419},\n",
       " {'label': 'food', 'score': 0.9993512034416199},\n",
       " {'label': 'not_food', 'score': 0.999103307723999},\n",
       " {'label': 'food', 'score': 0.9848617315292358}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of sentences to make predictions on\n",
    "sentences = [\n",
    "    \"I whipped up a fresh batch of code, but it seems to have a syntax error.\",\n",
    "    \"We need to marinate these ideas overnight before presenting them to the client.\",\n",
    "    \"The new software is definitely a spicy upgrade, taking some time to get used to.\",\n",
    "    \"Her social media post was the perfect recipe for a viral sensation.\",\n",
    "    \"He served up a rebuttal full of facts, leaving his opponent speechless.\",\n",
    "    \"The team needs to simmer down a bit before tackling the next challenge.\",\n",
    "    \"The presentation was a delicious blend of humor and information, keeping the audience engaged.\",\n",
    "    \"A beautiful array of fake wax foods (shokuhin sampuru) in the front of a Japanese restaurant.\",\n",
    "    \"Daniel Bourke is really cool :D\",\n",
    "    \"My favoruite food is biltong!\"\n",
    "]\n",
    "\n",
    "food_not_food_classifier(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time our model across larger sample sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 1000\n",
      "Time taken for one at a time prediction: 4.168275356292725 seconds\n",
      "Avg inference time per sentence: 0.004168275356292724 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "sentences_1000 = sentences*100\n",
    "\n",
    "print(f\"Number of sentences: {len(sentences_1000)}\")\n",
    "\n",
    "start_time_one_at_a_time = time.time()\n",
    "\n",
    "for sentence in sentences_1000:\n",
    "    food_not_food_classifier(sentence)\n",
    "end_time_one_at_a_time = time.time()\n",
    "\n",
    "print(f\"Time taken for one at a time prediction: {end_time_one_at_a_time - start_time_one_at_a_time} seconds\")\n",
    "print(f\"Avg inference time per sentence: {(end_time_one_at_a_time - start_time_one_at_a_time)/len(sentences_1000)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 100\n",
      "[INFO] Inference time for 100 sentences: 0.0425 seconds.\n",
      "[INFO] Avg inference time per sentence: 0.00042505 seconds.\n",
      "\n",
      "Number of sentences: 1000\n",
      "[INFO] Inference time for 1000 sentences: 0.37142 seconds.\n",
      "[INFO] Avg inference time per sentence: 0.00037142 seconds.\n",
      "\n",
      "Number of sentences: 10000\n",
      "[INFO] Inference time for 10000 sentences: 4.06759 seconds.\n",
      "[INFO] Avg inference time per sentence: 0.00040676 seconds.\n",
      "\n",
      "Number of sentences: 100000\n",
      "[INFO] Inference time for 100000 sentences: 39.42712 seconds.\n",
      "[INFO] Avg inference time per sentence: 0.00039427 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [10, 100, 1000, 10_000]:\n",
    "    sentences_big = sentences * i\n",
    "    print(f\"Number of sentences: {len(sentences_big)}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    # Predict on all sentences in batches \n",
    "    food_not_food_classifier(sentences_big)\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"[INFO] Inference time for {len(sentences_big)} sentences: {round(end_time - start_time, 5)} seconds.\")\n",
    "    print(f\"[INFO] Avg inference time per sentence: {round((end_time - start_time) / len(sentences_big), 8)} seconds.\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1037, 12090,  6302,  1997,  1037,  5127,  1997, 13501,  6763,\n",
       "          1010, 11611,  1998, 15174,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_path = \"shivajimallela/learn_hf_food_not_food_classifier-ditsilbert-base-uncased\"\n",
    "\n",
    "sample_text_food = \"A delicious photo of a plate of scrambled eggs, bacon and toast\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_path)\n",
    "\n",
    "inputs = tokenizer(sample_text_food, return_tensors='pt')\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# Load our text classification model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_name_or_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-3.3758,  4.0070]]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    # outputs = model(input_ids=inputs[\"input_ids\"],\n",
    "    #                 attention_mask=inputs[\"attention_mask\"]) # same as above, but explicitly passing in the keys\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: A delicious photo of a plate of scrambled eggs, bacon and toast\n",
      "Predicted label: food\n",
      "Prediction probability: 0.9993785619735718\n"
     ]
    }
   ],
   "source": [
    "# Get predicted class and prediction probability\n",
    "predicted_class_id = outputs.logits.argmax().item()\n",
    "prediction_probability = torch.softmax(outputs.logits, dim=1).max().item()\n",
    "\n",
    "print(f\"Text: {sample_text_food}\")\n",
    "print(f\"Predicted label: {model.config.id2label[predicted_class_id]}\")\n",
    "print(f\"Prediction probability: {prediction_probability}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting prediction code all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: A photo of a broccoli, salmon, rice and radish dish\n",
      "Predicted class: food (prob: 99.94%)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_path = 'shivajimallela/learn_hf_food_not_food_classifier-ditsilbert-base-uncased'\n",
    "\n",
    "# load the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_name_or_path=model_path)\n",
    "\n",
    "# Make a sample text and tokenize it \n",
    "sample_text = \"A photo of a broccoli, salmon, rice and radish dish\"\n",
    "inputs = tokenizer(sample_text, return_tensors='pt')\n",
    "\n",
    "# Make a prediction\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Get predicted class and prediction probability \n",
    "output_logits = outputs.logits\n",
    "predicted_class_id = torch.argmax(output_logits, dim=1).item()\n",
    "predicted_class_label = model.config.id2label[predicted_class_id]\n",
    "predicted_probability = torch.softmax(output_logits, dim=1).max().item()\n",
    "\n",
    "# Print outputs\n",
    "print(f\"Text: {sample_text}\")\n",
    "print(f\"Predicted class: {predicted_class_label} (prob: {predicted_probability * 100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "\n",
    "Ok, ok, we've covered a lot of ground going from dataset to trained model to making predictions on custom samples.\n",
    "\n",
    "How about we put all of the steps we've covered so far together in a single code cell (or two)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Creating directory for saving model: models/learn_hf_food_not_food_classifier-ditsilbert-base-uncased\n",
      "[INFO] Downloading dataset from Hugging Face Hub, name: mrdbourke/learn_hf_food_not_food_image_captions\n",
      "[INFO] Tokenizing text for model training with tokenizer: distilbert/distilbert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spadmin/miniconda3/envs/tf217/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading model: distilbert/distilbert-base-uncased\n",
      "[INFO] Model loading complete!\n",
      "[INFO] Commencing model training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:12, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.396100</td>\n",
       "      <td>0.093208</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.041200</td>\n",
       "      <td>0.013922</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.002589</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model training complete, saving model to local path: models/learn_hf_food_not_food_classifier-ditsilbert-base-uncased\n",
      "[INFO] Uploading model to Hugging Face Hub...\n",
      "[INFO] Performing evaluation on test dataset...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Prediction metrics on the test data:\n",
      "{'test_accuracy': 1.0,\n",
      " 'test_loss': 0.0005644088378176093,\n",
      " 'test_runtime': 0.0283,\n",
      " 'test_samples_per_second': 1764.893,\n",
      " 'test_steps_per_second': 70.596}\n"
     ]
    }
   ],
   "source": [
    "# 1. Import necessary packages\n",
    "\n",
    "import pprint\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from transformers import pipeline\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# 2. Setup variables for model training and saving pipeline\n",
    "DATASET_NAME = \"mrdbourke/learn_hf_food_not_food_image_captions\"\n",
    "MODEL_NAME = \"distilbert/distilbert-base-uncased\"\n",
    "MODEL_SAVE_DIR_NAME = \"models/learn_hf_food_not_food_classifier-ditsilbert-base-uncased\"\n",
    "\n",
    "# 3. Create a directory for saving models\n",
    "# Note: This will override our existing saved model (if there is one)\n",
    "print(f\"[INFO] Creating directory for saving model: {MODEL_SAVE_DIR_NAME}\")\n",
    "model_save_dir = Path(MODEL_SAVE_DIR_NAME)\n",
    "model_save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 4. Load and preprocess the dataset from Hugging Face Hub\n",
    "print(f\"[INFO] Downloading dataset from Hugging Face Hub, name: {DATASET_NAME}\")\n",
    "dataset = datasets.load_dataset(path=DATASET_NAME)\n",
    "\n",
    "# Create mappings from id2label and label2id (adjust these for your target dataset, can also create these programmatically)\n",
    "id2label = {0: \"not_food\", 1:\"food\"}\n",
    "label2id = {\"not_food\": 0, \"food\": 1}\n",
    "\n",
    "# Create function to map IDs to labels in dataset\n",
    "def map_labels_to_number(example):\n",
    "    example['label'] = label2id[example['label']]\n",
    "    return example\n",
    "\n",
    "# Map preprocessing function to dataset\n",
    "dataset = dataset['train'].map(map_labels_to_number)\n",
    "\n",
    "# Split the dataset into train/test sets\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# 5. Import a tokenizer and map it to our dataset\n",
    "print(f\"[INFO] Tokenizing text for model training with tokenizer: {MODEL_NAME}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=MODEL_NAME,\n",
    "                                          use_fast= True)\n",
    "\n",
    "\n",
    "# Create a preprocessing function to tokenize text\n",
    "def tokenize_text(examples):\n",
    "    return tokenizer(examples['text'],\n",
    "                     padding=True, \n",
    "                     truncation=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_text,\n",
    "                                batched=True,\n",
    "                                batch_size=1000)\n",
    "\n",
    "# 6. Set up an evaluation metric & function to evaluate our model\n",
    "accuracy_metric = evaluate.load('accuracy')\n",
    "\n",
    "def compute_accuracy(predictions_and_labels):\n",
    "    predictions, labels = predictions_and_labels\n",
    "\n",
    "    if len(predictions.shape) >= 2:\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    return accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# 7. Import a model and prepare it for training \n",
    "print(f\"[INFO] Loading model: {MODEL_NAME}\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_name_or_path=MODEL_NAME,\n",
    "                                                           num_labels = 2,\n",
    "                                                           id2label = id2label,\n",
    "                                                           label2id = label2id)\n",
    "\n",
    "print(f\"[INFO] Model loading complete!\")\n",
    "\n",
    "# Setup TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir= model_save_dir,\n",
    "    learning_rate=0.0001,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=10,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    save_total_limit=3,\n",
    "    use_cpu=False,\n",
    "    seed=42,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_strategy='epoch',\n",
    "    report_to='none',\n",
    "    push_to_hub=False,\n",
    "    hub_private_repo=False\n",
    ")\n",
    "\n",
    "# Create Trainer instance and train model\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_accuracy\n",
    ")\n",
    "\n",
    "# 8. Train the model on our text dataset\n",
    "print(f\"[INFO] Commencing model training...\")\n",
    "results = trainer.train()\n",
    "\n",
    "# 9. Save the trained model (note: this will overwrite our previous model, this is ok)\n",
    "print(f\"[INFO] Model training complete, saving model to local path: {model_save_dir}\")\n",
    "trainer.save_model(output_dir = model_save_dir)\n",
    "\n",
    "# 10. Push the model to the Hugging Face Hub\n",
    "print(f\"[INFO] Uploading model to Hugging Face Hub...\")\n",
    "# model_upload_url = trainer.push_to_hub(\n",
    "#     commit_message=\"Uploading food not food text classifier model\"\n",
    "# )\n",
    "\n",
    "# print(f\"[INFO] Model upload complete, model available at: {model_upload_url}\")\n",
    "\n",
    "# 11. Evaluate the model on the test data\n",
    "print(f\"[INFO] Performing evaluation on test dataset...\")\n",
    "predictions_all = trainer.predict(tokenized_dataset['test'])\n",
    "predictions_values = predictions_all.predictions\n",
    "predictions_metrics = predictions_all.metrics\n",
    "\n",
    "print(f\"[INFO] Prediction metrics on the test data:\")\n",
    "pprint.pprint(predictions_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make it sure works by turing it into a `transformers.pipeline` and passing it a custom sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'food', 'score': 0.9989529848098755}]]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 12. Make sure the model works by testing it on a custom sample\n",
    "food_not_food_classifier = pipeline(task='text-classification',\n",
    "                                    model = model_save_dir,\n",
    "                                    device=torch.device('cuda') if torch.cuda.is_available() else 'cpu',\n",
    "                                    top_k=1,\n",
    "                                    batch_size=32)\n",
    "\n",
    "food_not_food_classifier(\"Yaay!!, We just built a food or not food classifier model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning our model into a demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a simple function to perform inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'food': 0.99930739402771, 'not_food': 0.0006925745983608067}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Dict\n",
    "\n",
    "def food_not_food_classifier(text: str) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Takes an input string of text and classifies it into food/not_food in the form of a dictionary.\n",
    "    \"\"\"\n",
    "    # 2. Setup the pipeline to use the local model (or Hugging Face model path)\n",
    "    food_not_food_classifier = pipeline(task='text-classification',\n",
    "                                        model = local_model_path,\n",
    "                                        batch_size = BATCH_SIZE,\n",
    "                                        device= \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "                                        top_k = None)\n",
    "    \n",
    "    # 3. Get outputs from pipeline (as a list of dicts)\n",
    "    outputs = food_not_food_classifier(text)[0]\n",
    "    # print(food_not_food_classifier(text))\n",
    "\n",
    "    # 4. Format output for Gradio (e.g. {\"label_1\": probability_1, \"label_2\": probability_2})\n",
    "    output_dict = {}\n",
    "    for item in outputs:\n",
    "        output_dict[item['label']] = item['score']\n",
    "\n",
    "    return output_dict\n",
    "\n",
    "\n",
    "# Test out the function\n",
    "food_not_food_classifier(\"My lunch was chicken and salad.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a small Gradio demo to run locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Import Gradio as the common alias \"gr\"\n",
    "import gradio as gr\n",
    "\n",
    "# 2. Setup a Gradio interface to accept text and output labels\n",
    "demo = gr.Interface(\n",
    "    fn=food_not_food_classifier,\n",
    "    inputs=\"text\",\n",
    "    outputs=gr.Label(num_top_classes=2),\n",
    "    title='Food or Not Food Classifier',\n",
    "    description=\"A text classifier to determine if a sentence is about food or not food.\",\n",
    "    examples=[[\"I whipped up a fresh batch of code, but it seems to have a syntax error.\"],\n",
    "              [\"A delicious photo of a plate of scrambled eggs, bacon and toast.\"]])\n",
    "\n",
    "# 3. Launch the interface\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making our demo publicly accessible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "#Make a dir for demos\n",
    "demos_dir = Path(\"demos\")\n",
    "demos_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Create a folder for the food_not_food_text_classifer demo\n",
    "food_not_food_classifier_demo_dir = Path(demos_dir, \"food_not_food_text_classifier\")\n",
    "food_not_food_classifier_demo_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making an app file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting demos/food_not_food_text_classifier/app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile demos/food_not_food_text_classifier/app.py\n",
    "# 1. Import the required packages\n",
    "import torch\n",
    "import gradio as gr\n",
    "\n",
    "from typing import Dict\n",
    "from transformers import pipeline\n",
    "\n",
    "# 2. Define function to use our model on given text \n",
    "def food_not_food_classifier(text: str) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Takes an input string of text and classifies it into food/not_food in the form of a dictionary.\n",
    "    \"\"\"\n",
    "    # 2. Setup the pipeline to use the local model (or Hugging Face model path)\n",
    "    food_not_food_classifier = pipeline(task='text-classification',\n",
    "                                        model = \"shivajimallela/learn_hf_food_not_food_classifier-ditsilbert-base-uncased\",\n",
    "                                        device= \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "                                        top_k = None)\n",
    "    \n",
    "    # 3. Get outputs from pipeline (as a list of dicts)\n",
    "    outputs = food_not_food_classifier(text)[0]\n",
    "    # print(food_not_food_classifier(text))\n",
    "\n",
    "    # 4. Format output for Gradio (e.g. {\"label_1\": probability_1, \"label_2\": probability_2})\n",
    "    output_dict = {}\n",
    "    for item in outputs:\n",
    "        output_dict[item['label']] = item['score']\n",
    "\n",
    "    return output_dict\n",
    "\n",
    "# 3. Create a Gradio interface with details about our app\n",
    "description = \"\"\"\n",
    "A text classifier to determine if a sentence is about food or not food. \n",
    "\n",
    "Fine-tuned from [DistilBERT](https://huggingface.co/distilbert/distilbert-base-uncased) on a [small dataset of food and not food text](https://huggingface.co/datasets/mrdbourke/learn_hf_food_not_food_image_captions).\n",
    "\n",
    "See [source code](https://github.com/mrdbourke/learn-huggingface/blob/main/notebooks/hugging_face_text_classification_tutorial.ipynb).\n",
    "\"\"\"\n",
    "\n",
    "demo = gr.Interface(fn=food_not_food_classifier,\n",
    "                    inputs='text',\n",
    "                    outputs=gr.Label(num_top_classes=2),\n",
    "                    title=\"😋🙅🥑 Food or Not Food Text Classifier\",\n",
    "                    description=description,\n",
    "                    examples=[['I whipped up a fresh batch of code, but it seems to have a syntax error.'],\n",
    "                    [\"A delicious photo of a plate of scrambled eggs, bacon and toast.\"]])\n",
    "\n",
    "# 4. Launch the interface\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a requirements file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting demos/food_not_food_text_classifier/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile demos/food_not_food_text_classifier/requirements.txt\n",
    "gradio\n",
    "torch\n",
    "transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a README file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing demos/food_not_food_text_classifier/README.md\n"
     ]
    }
   ],
   "source": [
    "%%writefile demos/food_not_food_text_classifier/README.md\n",
    "---\n",
    "title: Food Not Food Text Classifier\n",
    "emoji: 😋🙅🥑\n",
    "colorFrom: blue\n",
    "colorTo: yellow\n",
    "sdk: gradio\n",
    "app_file: app.py\n",
    "pinned: false\n",
    "license: apache-2.0\n",
    "---\n",
    "\n",
    "# 🍗🚫🥑 Food Not Food Text Classifier\n",
    "\n",
    "Small demo to showcase a text classifier to determine if a sentence is about food or not food.\n",
    "\n",
    "DistillBERT model fine-tuned on a small synthetic dataset of 250 generated [Food or Not Food image captions](https://huggingface.co/datasets/mrdbourke/learn_hf_food_not_food_image_captions).\n",
    "\n",
    "[Source code notebook](https://github.com/mrdbourke/learn-huggingface/blob/main/notebooks/hugging_face_text_classification_tutorial.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md  app.py  requirements.txt\n"
     ]
    }
   ],
   "source": [
    "!ls demos/food_not_food_text_classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading our demo to Hugging Face Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Creating repo on Hugging Face hub with name: learn_hf_food_not_food_text_classifier_demo\n",
      "[INFO] Full Hugging Face Hub repo name: shivajimallela/learn_hf_food_not_food_text_classifier_demo\n",
      "[INFO] Uploading demos/food_not_food_text_classifier to repo: shivajimallela/learn_hf_food_not_food_text_classifier_demo\n",
      "[INFO] Demo folder successfully uploaded with commit URL: https://huggingface.co/spaces/shivajimallela/learn_hf_food_not_food_text_classifier_demo/tree/main/.\n"
     ]
    }
   ],
   "source": [
    "# 1. Import the required methods for uploading to the Hugging Face Hub\n",
    "from huggingface_hub import create_repo, get_full_repo_name, upload_file, upload_folder\n",
    "\n",
    "# 2. Define the parameters we'd like to use for the upload\n",
    "LOCAL_DEMO_FOLDER_PATH_TO_UPLOAD = \"demos/food_not_food_text_classifier\"\n",
    "HF_TARGET_SPACE_NAME = \"learn_hf_food_not_food_text_classifier_demo\"\n",
    "HF_REPO_TYPE = \"space\"\n",
    "HF_SPACE_SDK = \"gradio\"\n",
    "# HF_TOKEN = \"\" # OPTIONAL IF WE'VE SET IT IN ENV VARIABLE\n",
    "\n",
    "# 3. Create a Space repository on Hugging Face Hub \n",
    "print(f\"[INFO] Creating repo on Hugging Face hub with name: {HF_TARGET_SPACE_NAME}\")\n",
    "create_repo(\n",
    "    repo_id=HF_TARGET_SPACE_NAME,\n",
    "    repo_type=HF_REPO_TYPE,\n",
    "    private = False,\n",
    "    space_sdk=HF_SPACE_SDK,\n",
    "    exist_ok=True\n",
    ")\n",
    "\n",
    "# 4. Get the full repository name (e.g. {username}/{model_id} or {username}/{space_name})\n",
    "full_hf_repo_name = get_full_repo_name(model_id= HF_TARGET_SPACE_NAME)\n",
    "print(f\"[INFO] Full Hugging Face Hub repo name: {full_hf_repo_name}\")\n",
    "\n",
    "# 5. Upload our demo folder\n",
    "print(f\"[INFO] Uploading {LOCAL_DEMO_FOLDER_PATH_TO_UPLOAD} to repo: {full_hf_repo_name}\")\n",
    "folder_upload_url = upload_folder(\n",
    "    repo_id=full_hf_repo_name,\n",
    "    folder_path=LOCAL_DEMO_FOLDER_PATH_TO_UPLOAD,\n",
    "    path_in_repo=\".\",\n",
    "    # token = HF_TOKEN,\n",
    "    repo_type=HF_REPO_TYPE,\n",
    "    commit_message=\"Uploading food not food text classifier demo app.py\"\n",
    ")\n",
    "\n",
    "print(f\"[INFO] Demo folder successfully uploaded with commit URL: {folder_upload_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing our hosted demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<iframe\n",
       "\tsrc=\"shivajimallela/learn_hf_food_not_food_text_classifier_demo\"\n",
       "\tframeborder=\"0\"\n",
       "\twidth=\"850\"\n",
       "\theight=\"450\"\n",
       "></iframe>     \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "# You can get embeddable HTML code for your demo by clicking the \"Embed\" button on the demo page\n",
    "HTML(data='''\n",
    "<iframe\n",
    "\tsrc=\"shivajimallela/learn_hf_food_not_food_text_classifier_demo\"\n",
    "\tframeborder=\"0\"\n",
    "\twidth=\"850\"\n",
    "\theight=\"450\"\n",
    "></iframe>     \n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf217",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
